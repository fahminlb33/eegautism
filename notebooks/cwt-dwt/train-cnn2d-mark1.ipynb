{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 17:41:36.470991: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-20 17:41:36.486491: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-20 17:41:36.490553: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-20 17:41:36.501950: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-20 17:41:37.283739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "html[data-theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 508MB\n",
       "Dimensions:   (samples: 246, frequency: 127, time: 127, channels: 16)\n",
       "Dimensions without coordinates: samples, frequency, time, channels\n",
       "Data variables:\n",
       "    features  (samples, frequency, time, channels) float64 508MB ...\n",
       "    labels    (samples) int64 2kB ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-02055522-e4a5-488c-abe4-d9ba2fac9d92' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-02055522-e4a5-488c-abe4-d9ba2fac9d92' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span>samples</span>: 246</li><li><span>frequency</span>: 127</li><li><span>time</span>: 127</li><li><span>channels</span>: 16</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-80b719ea-fd6d-4f8a-a6ce-6fc6bad37537' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-80b719ea-fd6d-4f8a-a6ce-6fc6bad37537' class='xr-section-summary'  title='Expand/collapse section'>Coordinates: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-c01846ba-fcdf-414e-8c1d-b21e1cc5fd05' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c01846ba-fcdf-414e-8c1d-b21e1cc5fd05' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>features</span></div><div class='xr-var-dims'>(samples, frequency, time, channels)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-0f88c27b-db13-4ba9-9681-7ab0e8f76401' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0f88c27b-db13-4ba9-9681-7ab0e8f76401' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e0269a51-56b0-44a7-86ca-e688e4d6db98' class='xr-var-data-in' type='checkbox'><label for='data-e0269a51-56b0-44a7-86ca-e688e4d6db98' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[63483744 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>labels</span></div><div class='xr-var-dims'>(samples)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-14f7db35-8b78-47a4-a370-6c5aa12e2739' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-14f7db35-8b78-47a4-a370-6c5aa12e2739' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f81cdb39-da36-4d97-b66e-c0b6b76b7fa4' class='xr-var-data-in' type='checkbox'><label for='data-f81cdb39-da36-4d97-b66e-c0b6b76b7fa4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[246 values with dtype=int64]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-0923e159-8dc9-4963-b0cb-5e49e0ca8bc3' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-0923e159-8dc9-4963-b0cb-5e49e0ca8bc3' class='xr-section-summary'  title='Expand/collapse section'>Indexes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-00db80e6-f40b-4e77-8350-9dc1173eab58' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-00db80e6-f40b-4e77-8350-9dc1173eab58' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 508MB\n",
       "Dimensions:   (samples: 246, frequency: 127, time: 127, channels: 16)\n",
       "Dimensions without coordinates: samples, frequency, time, channels\n",
       "Data variables:\n",
       "    features  (samples, frequency, time, channels) float64 508MB ...\n",
       "    labels    (samples) int64 2kB ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = xr.open_dataset(\"../data/dataset_no_overlap_60.nc\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((164, 127, 127, 16), (82, 127, 127, 16), (164,), (82,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ds[\"features\"].to_numpy(), ds[\"labels\"].to_numpy(), test_size=0.33, random_state=22, stratify=ds[\"labels\"])\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = (X_train - X_train.mean(axis=(1, 2))[:, np.newaxis, np.newaxis, :]) / X_train.std(axis=(1, 2))[:, np.newaxis, np.newaxis, :]\n",
    "X_test_scaled = (X_test - X_test.max(axis=(1, 2))[:, np.newaxis, np.newaxis, :]) / X_test.std(axis=(1, 2))[:, np.newaxis, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724150499.845486   33364 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724150499.876036   33364 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724150499.876101   33364 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724150499.879734   33364 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724150499.879822   33364 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724150499.879853   33364 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724150500.045698   33364 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724150500.045785   33364 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 17:41:40.045796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1724150500.045849   33364 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 17:41:40.045869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train)).shuffle(X_train.shape[0]).batch(8).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test_scaled, y_test)).shuffle(X_test.shape[0]).batch(8).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding=\"same\")(inputs)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, kernel_size=(2, 2), padding=\"same\")(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, kernel_size=(2, 2), padding=\"same\")(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "# x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7200</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,373,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7200\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m7,373,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,025\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,387,745</span> (28.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,387,745\u001b[0m (28.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,387,745</span> (28.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,387,745\u001b[0m (28.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    # loss=tf.keras.losses.BinaryFocalCrossentropy(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724150504.103072   33596 service.cc:146] XLA service 0x7f2a180107d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1724150504.103124   33596 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-08-20 17:41:44.182834: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-20 17:41:44.419022: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/21\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5638 - auc: 0.5624 - fn: 13.6429 - fp: 12.0000 - loss: 1.5502 - prc: 0.6410 - precision: 0.6124 - recall: 0.5783 - tn: 9.7143 - tp: 24.6429          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 17:41:46.525581: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_2', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "I0000 00:00:1724150506.534519   33596 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5691 - auc: 0.5373 - fn: 18.3333 - fp: 18.8571 - loss: 1.4228 - prc: 0.6480 - precision: 0.6356 - recall: 0.6236 - tn: 10.9524 - tp: 39.6667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 17:41:49.066937: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_2', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 346ms/step - accuracy: 0.5698 - auc: 0.5345 - fn: 18.8636 - fp: 19.7273 - loss: 1.4083 - prc: 0.6486 - precision: 0.6378 - recall: 0.6286 - tn: 11.0909 - tp: 41.5909 - val_accuracy: 0.5000 - val_auc: 0.4948 - val_fn: 31.0000 - val_fp: 10.0000 - val_loss: 0.7041 - val_prc: 0.7166 - val_precision: 0.7143 - val_recall: 0.4464 - val_tn: 16.0000 - val_tp: 25.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6717 - auc: 0.5579 - fn: 3.8182 - fp: 26.6818 - loss: 0.6373 - prc: 0.7060 - precision: 0.6882 - recall: 0.9558 - tn: 2.0000 - tp: 58.7727 - val_accuracy: 0.6098 - val_auc: 0.4227 - val_fn: 7.0000 - val_fp: 25.0000 - val_loss: 0.6806 - val_prc: 0.6460 - val_precision: 0.6622 - val_recall: 0.8750 - val_tn: 1.0000 - val_tp: 49.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6779 - auc: 0.6569 - fn: 11.2727 - fp: 16.9091 - loss: 0.6054 - prc: 0.8023 - precision: 0.7631 - recall: 0.7888 - tn: 9.0455 - tp: 54.0455 - val_accuracy: 0.5976 - val_auc: 0.4567 - val_fn: 11.0000 - val_fp: 22.0000 - val_loss: 0.6819 - val_prc: 0.6998 - val_precision: 0.6716 - val_recall: 0.8036 - val_tn: 4.0000 - val_tp: 45.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7891 - auc: 0.8209 - fn: 8.1364 - fp: 11.8636 - loss: 0.5354 - prc: 0.8984 - precision: 0.8299 - recall: 0.8650 - tn: 16.5000 - tp: 54.7727 - val_accuracy: 0.6341 - val_auc: 0.5069 - val_fn: 9.0000 - val_fp: 21.0000 - val_loss: 0.6567 - val_prc: 0.7246 - val_precision: 0.6912 - val_recall: 0.8393 - val_tn: 5.0000 - val_tp: 47.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7403 - auc: 0.8229 - fn: 14.3182 - fp: 8.2727 - loss: 0.5250 - prc: 0.9046 - precision: 0.8650 - recall: 0.7126 - tn: 22.5909 - tp: 46.0909 - val_accuracy: 0.4512 - val_auc: 0.5017 - val_fn: 36.0000 - val_fp: 9.0000 - val_loss: 0.8161 - val_prc: 0.7186 - val_precision: 0.6897 - val_recall: 0.3571 - val_tn: 17.0000 - val_tp: 20.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8442 - auc: 0.8966 - fn: 3.7727 - fp: 11.2727 - loss: 0.3771 - prc: 0.9526 - precision: 0.8560 - recall: 0.9348 - tn: 16.1818 - tp: 60.0455 - val_accuracy: 0.6463 - val_auc: 0.5209 - val_fn: 9.0000 - val_fp: 20.0000 - val_loss: 0.7592 - val_prc: 0.7226 - val_precision: 0.7015 - val_recall: 0.8393 - val_tn: 6.0000 - val_tp: 47.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8825 - auc: 0.9565 - fn: 4.0000 - fp: 7.2727 - loss: 0.2773 - prc: 0.9825 - precision: 0.8996 - recall: 0.9414 - tn: 19.8182 - tp: 60.1818 - val_accuracy: 0.5610 - val_auc: 0.5457 - val_fn: 17.0000 - val_fp: 19.0000 - val_loss: 0.6683 - val_prc: 0.7561 - val_precision: 0.6724 - val_recall: 0.6964 - val_tn: 7.0000 - val_tp: 39.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9894 - auc: 0.9981 - fn: 0.7273 - fp: 0.5455 - loss: 0.0974 - prc: 0.9992 - precision: 0.9950 - recall: 0.9898 - tn: 27.8636 - tp: 62.1364 - val_accuracy: 0.5366 - val_auc: 0.4859 - val_fn: 20.0000 - val_fp: 18.0000 - val_loss: 0.8995 - val_prc: 0.7186 - val_precision: 0.6667 - val_recall: 0.6429 - val_tn: 8.0000 - val_tp: 36.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9518 - auc: 0.9870 - fn: 2.7727 - fp: 2.2273 - loss: 0.1285 - prc: 0.9935 - precision: 0.9707 - recall: 0.9586 - tn: 26.9545 - tp: 59.3182 - val_accuracy: 0.6585 - val_auc: 0.4629 - val_fn: 4.0000 - val_fp: 24.0000 - val_loss: 1.5483 - val_prc: 0.6636 - val_precision: 0.6842 - val_recall: 0.9286 - val_tn: 2.0000 - val_tp: 52.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9464 - auc: 0.9893 - fn: 2.5455 - fp: 1.9091 - loss: 0.1317 - prc: 0.9957 - precision: 0.9721 - recall: 0.9547 - tn: 24.3182 - tp: 62.5000 - val_accuracy: 0.5488 - val_auc: 0.5422 - val_fn: 20.0000 - val_fp: 17.0000 - val_loss: 0.8230 - val_prc: 0.7527 - val_precision: 0.6792 - val_recall: 0.6429 - val_tn: 9.0000 - val_tp: 36.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9908 - auc: 0.9988 - fn: 0.8182 - fp: 0.0000e+00 - loss: 0.0548 - prc: 0.9994 - precision: 1.0000 - recall: 0.9862 - tn: 28.6818 - tp: 61.7727 - val_accuracy: 0.5366 - val_auc: 0.5312 - val_fn: 18.0000 - val_fp: 20.0000 - val_loss: 0.9108 - val_prc: 0.7596 - val_precision: 0.6552 - val_recall: 0.6786 - val_tn: 6.0000 - val_tp: 38.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9979 - auc: 0.9999 - fn: 0.0000e+00 - fp: 0.3182 - loss: 0.0239 - prc: 1.0000 - precision: 0.9969 - recall: 1.0000 - tn: 27.9091 - tp: 63.0455 - val_accuracy: 0.5244 - val_auc: 0.5038 - val_fn: 23.0000 - val_fp: 16.0000 - val_loss: 1.0182 - val_prc: 0.7321 - val_precision: 0.6735 - val_recall: 0.5893 - val_tn: 10.0000 - val_tp: 33.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 0.0162 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.6364 - tp: 62.6364 - val_accuracy: 0.5366 - val_auc: 0.4986 - val_fn: 21.0000 - val_fp: 17.0000 - val_loss: 1.1696 - val_prc: 0.7196 - val_precision: 0.6731 - val_recall: 0.6250 - val_tn: 9.0000 - val_tp: 35.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 0.0030 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.7727 - tp: 63.5000 - val_accuracy: 0.5244 - val_auc: 0.5000 - val_fn: 22.0000 - val_fp: 17.0000 - val_loss: 1.2992 - val_prc: 0.6979 - val_precision: 0.6667 - val_recall: 0.6071 - val_tn: 9.0000 - val_tp: 34.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 0.0018 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.1818 - tp: 63.0909 - val_accuracy: 0.5488 - val_auc: 0.5151 - val_fn: 20.0000 - val_fp: 17.0000 - val_loss: 1.2826 - val_prc: 0.7046 - val_precision: 0.6792 - val_recall: 0.6429 - val_tn: 9.0000 - val_tp: 36.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 5.2331e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.9545 - tp: 60.3182 - val_accuracy: 0.5610 - val_auc: 0.5148 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.2677 - val_prc: 0.7043 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.6307e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.8636 - tp: 60.4091 - val_accuracy: 0.5610 - val_auc: 0.5158 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.2770 - val_prc: 0.7006 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.4564e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.5909 - tp: 62.6818 - val_accuracy: 0.5488 - val_auc: 0.5179 - val_fn: 20.0000 - val_fp: 17.0000 - val_loss: 1.2903 - val_prc: 0.7020 - val_precision: 0.6792 - val_recall: 0.6429 - val_tn: 9.0000 - val_tp: 36.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 2.6963e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 33.0455 - tp: 58.2273 - val_accuracy: 0.5488 - val_auc: 0.5223 - val_fn: 20.0000 - val_fp: 17.0000 - val_loss: 1.3009 - val_prc: 0.7040 - val_precision: 0.6792 - val_recall: 0.6429 - val_tn: 9.0000 - val_tp: 36.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.7085e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.6364 - tp: 60.6364 - val_accuracy: 0.5366 - val_auc: 0.5244 - val_fn: 21.0000 - val_fp: 17.0000 - val_loss: 1.3056 - val_prc: 0.7051 - val_precision: 0.6731 - val_recall: 0.6250 - val_tn: 9.0000 - val_tp: 35.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.8227e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.9545 - tp: 60.3182 - val_accuracy: 0.5366 - val_auc: 0.5227 - val_fn: 21.0000 - val_fp: 17.0000 - val_loss: 1.3118 - val_prc: 0.7041 - val_precision: 0.6731 - val_recall: 0.6250 - val_tn: 9.0000 - val_tp: 35.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.0919e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.1818 - tp: 63.0909 - val_accuracy: 0.5488 - val_auc: 0.5213 - val_fn: 20.0000 - val_fp: 17.0000 - val_loss: 1.3201 - val_prc: 0.7030 - val_precision: 0.6792 - val_recall: 0.6429 - val_tn: 9.0000 - val_tp: 36.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 2.2336e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.3182 - tp: 63.9545 - val_accuracy: 0.5366 - val_auc: 0.5206 - val_fn: 21.0000 - val_fp: 17.0000 - val_loss: 1.3242 - val_prc: 0.7026 - val_precision: 0.6731 - val_recall: 0.6250 - val_tn: 9.0000 - val_tp: 35.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.7186e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.2727 - tp: 63.0000 - val_accuracy: 0.5366 - val_auc: 0.5209 - val_fn: 21.0000 - val_fp: 17.0000 - val_loss: 1.3295 - val_prc: 0.7039 - val_precision: 0.6731 - val_recall: 0.6250 - val_tn: 9.0000 - val_tp: 35.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.3938e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.5000 - tp: 63.7727 - val_accuracy: 0.5366 - val_auc: 0.5220 - val_fn: 21.0000 - val_fp: 17.0000 - val_loss: 1.3361 - val_prc: 0.7047 - val_precision: 0.6731 - val_recall: 0.6250 - val_tn: 9.0000 - val_tp: 35.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.5418e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.5455 - tp: 62.7273 - val_accuracy: 0.5366 - val_auc: 0.5227 - val_fn: 21.0000 - val_fp: 17.0000 - val_loss: 1.3427 - val_prc: 0.7047 - val_precision: 0.6731 - val_recall: 0.6250 - val_tn: 9.0000 - val_tp: 35.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.2365e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.4545 - tp: 62.8182 - val_accuracy: 0.5366 - val_auc: 0.5216 - val_fn: 21.0000 - val_fp: 17.0000 - val_loss: 1.3462 - val_prc: 0.7036 - val_precision: 0.6731 - val_recall: 0.6250 - val_tn: 9.0000 - val_tp: 35.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.0513e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.4545 - tp: 63.8182 - val_accuracy: 0.5488 - val_auc: 0.5216 - val_fn: 20.0000 - val_fp: 17.0000 - val_loss: 1.3517 - val_prc: 0.7036 - val_precision: 0.6792 - val_recall: 0.6429 - val_tn: 9.0000 - val_tp: 36.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 8.5042e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.0455 - tp: 62.2273 - val_accuracy: 0.5488 - val_auc: 0.5220 - val_fn: 20.0000 - val_fp: 17.0000 - val_loss: 1.3568 - val_prc: 0.7040 - val_precision: 0.6792 - val_recall: 0.6429 - val_tn: 9.0000 - val_tp: 36.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 8.4266e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.2273 - tp: 61.0455 - val_accuracy: 0.5488 - val_auc: 0.5199 - val_fn: 20.0000 - val_fp: 17.0000 - val_loss: 1.3604 - val_prc: 0.7029 - val_precision: 0.6792 - val_recall: 0.6429 - val_tn: 9.0000 - val_tp: 36.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.1645e-04 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.7727 - tp: 62.5000 - val_accuracy: 0.5610 - val_auc: 0.5185 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.3652 - val_prc: 0.7025 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 8.2825e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.2727 - tp: 63.0000 - val_accuracy: 0.5610 - val_auc: 0.5199 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.3682 - val_prc: 0.7035 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 6.6795e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.8636 - tp: 63.4091 - val_accuracy: 0.5610 - val_auc: 0.5192 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.3738 - val_prc: 0.7034 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 5.2259e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.5909 - tp: 63.6818 - val_accuracy: 0.5610 - val_auc: 0.5196 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.3783 - val_prc: 0.7038 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 8.0723e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.2727 - tp: 64.0000 - val_accuracy: 0.5610 - val_auc: 0.5189 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.3824 - val_prc: 0.7036 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 9.7325e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.6818 - tp: 63.5909 - val_accuracy: 0.5610 - val_auc: 0.5199 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.3873 - val_prc: 0.7042 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 6.5312e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.8182 - tp: 63.4545 - val_accuracy: 0.5610 - val_auc: 0.5209 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.3901 - val_prc: 0.7047 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 9.1294e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.4091 - tp: 62.8636 - val_accuracy: 0.5610 - val_auc: 0.5230 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.3948 - val_prc: 0.7071 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 6.3062e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.7727 - tp: 60.5000 - val_accuracy: 0.5488 - val_auc: 0.5227 - val_fn: 20.0000 - val_fp: 17.0000 - val_loss: 1.3981 - val_prc: 0.7069 - val_precision: 0.6792 - val_recall: 0.6429 - val_tn: 9.0000 - val_tp: 36.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 4.3039e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.6364 - tp: 61.6364 - val_accuracy: 0.5610 - val_auc: 0.5254 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4028 - val_prc: 0.7091 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 5.3690e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.0909 - tp: 64.1818 - val_accuracy: 0.5610 - val_auc: 0.5244 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4069 - val_prc: 0.7082 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 6.5908e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 25.6364 - tp: 65.6364 - val_accuracy: 0.5610 - val_auc: 0.5247 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4104 - val_prc: 0.7082 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 4.4650e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 31.7727 - tp: 59.5000 - val_accuracy: 0.5610 - val_auc: 0.5258 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4137 - val_prc: 0.7089 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 4.8694e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.0909 - tp: 63.1818 - val_accuracy: 0.5610 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4173 - val_prc: 0.7126 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 5.0286e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.6818 - tp: 60.5909 - val_accuracy: 0.5610 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4217 - val_prc: 0.7127 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 5.7401e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.5909 - tp: 63.6818 - val_accuracy: 0.5610 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4253 - val_prc: 0.7126 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 2.6757e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.2727 - tp: 62.0000 - val_accuracy: 0.5610 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4286 - val_prc: 0.7124 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.0845e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.3182 - tp: 62.9545 - val_accuracy: 0.5610 - val_auc: 0.5306 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4308 - val_prc: 0.7134 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.2733e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 31.3182 - tp: 59.9545 - val_accuracy: 0.5610 - val_auc: 0.5302 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4339 - val_prc: 0.7131 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.0347e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 26.5000 - tp: 64.7727 - val_accuracy: 0.5610 - val_auc: 0.5285 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4376 - val_prc: 0.7126 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - auc: 0.9545 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 4.5244e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.6364 - tp: 62.6364 - val_accuracy: 0.5610 - val_auc: 0.5282 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4419 - val_prc: 0.7123 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.3976e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 31.3636 - tp: 59.9091 - val_accuracy: 0.5610 - val_auc: 0.5268 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4444 - val_prc: 0.7113 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.3129e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.5455 - tp: 61.7273 - val_accuracy: 0.5610 - val_auc: 0.5271 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4476 - val_prc: 0.7115 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 4.0867e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 25.9545 - tp: 65.3182 - val_accuracy: 0.5610 - val_auc: 0.5275 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4502 - val_prc: 0.7116 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 2.9807e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.0455 - tp: 61.2273 - val_accuracy: 0.5610 - val_auc: 0.5275 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4545 - val_prc: 0.7118 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.4752e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 32.1818 - tp: 59.0909 - val_accuracy: 0.5610 - val_auc: 0.5271 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4590 - val_prc: 0.7114 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 2.6995e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.0455 - tp: 61.2273 - val_accuracy: 0.5610 - val_auc: 0.5271 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4607 - val_prc: 0.7114 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.1801e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.1364 - tp: 62.1364 - val_accuracy: 0.5610 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4633 - val_prc: 0.7117 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 2.7768e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.6364 - tp: 62.6364 - val_accuracy: 0.5610 - val_auc: 0.5282 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4669 - val_prc: 0.7143 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 2.4539e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.0909 - tp: 63.1818 - val_accuracy: 0.5610 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4692 - val_prc: 0.7142 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 2.4056e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.4545 - tp: 60.8182 - val_accuracy: 0.5610 - val_auc: 0.5275 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4715 - val_prc: 0.7138 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 2.4862e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.9091 - tp: 62.3636 - val_accuracy: 0.5610 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4737 - val_prc: 0.7139 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 3.4392e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.4091 - tp: 63.8636 - val_accuracy: 0.5610 - val_auc: 0.5288 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4772 - val_prc: 0.7145 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 0.9545 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.9056e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.5909 - tp: 63.6818 - val_accuracy: 0.5610 - val_auc: 0.5292 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4797 - val_prc: 0.7151 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.5066e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.5000 - tp: 63.7727 - val_accuracy: 0.5732 - val_auc: 0.5292 - val_fn: 18.0000 - val_fp: 17.0000 - val_loss: 1.4825 - val_prc: 0.7151 - val_precision: 0.6909 - val_recall: 0.6786 - val_tn: 9.0000 - val_tp: 38.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 2.2335e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.5909 - tp: 62.6818 - val_accuracy: 0.5732 - val_auc: 0.5285 - val_fn: 18.0000 - val_fp: 17.0000 - val_loss: 1.4852 - val_prc: 0.7148 - val_precision: 0.6909 - val_recall: 0.6786 - val_tn: 9.0000 - val_tp: 38.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.4227e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.4091 - tp: 62.8636 - val_accuracy: 0.5610 - val_auc: 0.5295 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4877 - val_prc: 0.7150 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.9516e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 26.0909 - tp: 65.1818 - val_accuracy: 0.5610 - val_auc: 0.5295 - val_fn: 19.0000 - val_fp: 17.0000 - val_loss: 1.4907 - val_prc: 0.7152 - val_precision: 0.6852 - val_recall: 0.6607 - val_tn: 9.0000 - val_tp: 37.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.7904e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.4545 - tp: 62.8182 - val_accuracy: 0.5732 - val_auc: 0.5306 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.4929 - val_prc: 0.7161 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.4268e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 26.1818 - tp: 65.0909 - val_accuracy: 0.5732 - val_auc: 0.5302 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.4953 - val_prc: 0.7158 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.9471e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.6818 - tp: 62.5909 - val_accuracy: 0.5732 - val_auc: 0.5302 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.4983 - val_prc: 0.7158 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.3140e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.0909 - tp: 61.1818 - val_accuracy: 0.5732 - val_auc: 0.5302 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5008 - val_prc: 0.7158 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.5404e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.0455 - tp: 63.2273 - val_accuracy: 0.5732 - val_auc: 0.5288 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5027 - val_prc: 0.7143 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.0726e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.0455 - tp: 64.2273 - val_accuracy: 0.5732 - val_auc: 0.5288 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5051 - val_prc: 0.7143 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.4436e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.7273 - tp: 61.5455 - val_accuracy: 0.5732 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5081 - val_prc: 0.7137 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.2688e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.2273 - tp: 64.0455 - val_accuracy: 0.5732 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5102 - val_prc: 0.7137 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.7509e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 26.8636 - tp: 64.4091 - val_accuracy: 0.5732 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5130 - val_prc: 0.7137 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.5056e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.5000 - tp: 61.7727 - val_accuracy: 0.5732 - val_auc: 0.5282 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5155 - val_prc: 0.7137 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.1000e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.7273 - tp: 61.5455 - val_accuracy: 0.5732 - val_auc: 0.5282 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5174 - val_prc: 0.7137 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.3598e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.1818 - tp: 62.0909 - val_accuracy: 0.5732 - val_auc: 0.5271 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5202 - val_prc: 0.7132 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.1917e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.6364 - tp: 60.6364 - val_accuracy: 0.5732 - val_auc: 0.5264 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5223 - val_prc: 0.7128 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.4794e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.5909 - tp: 61.6818 - val_accuracy: 0.5732 - val_auc: 0.5268 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5246 - val_prc: 0.7130 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.5683e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 30.8182 - tp: 60.4545 - val_accuracy: 0.5732 - val_auc: 0.5275 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5274 - val_prc: 0.7132 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.1636e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.8636 - tp: 62.4091 - val_accuracy: 0.5732 - val_auc: 0.5264 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5296 - val_prc: 0.7128 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - auc: 0.9545 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 8.6336e-06 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.0000 - tp: 64.2727 - val_accuracy: 0.5732 - val_auc: 0.5264 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5317 - val_prc: 0.7128 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.2709e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.6364 - tp: 63.6364 - val_accuracy: 0.5732 - val_auc: 0.5275 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5342 - val_prc: 0.7132 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.6194e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.4545 - tp: 62.8182 - val_accuracy: 0.5732 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5359 - val_prc: 0.7132 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 0.9545 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.1780e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.0909 - tp: 63.1818 - val_accuracy: 0.5732 - val_auc: 0.5282 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5388 - val_prc: 0.7133 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.3612e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.8182 - tp: 62.4545 - val_accuracy: 0.5732 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5409 - val_prc: 0.7132 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.0122e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.9545 - tp: 62.3182 - val_accuracy: 0.5732 - val_auc: 0.5282 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5428 - val_prc: 0.7133 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.3409e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.5909 - tp: 62.6818 - val_accuracy: 0.5732 - val_auc: 0.5275 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5458 - val_prc: 0.7130 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.0700e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 26.8636 - tp: 64.4091 - val_accuracy: 0.5732 - val_auc: 0.5275 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5473 - val_prc: 0.7130 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 8.6254e-06 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 28.9091 - tp: 62.3636 - val_accuracy: 0.5732 - val_auc: 0.5278 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5500 - val_prc: 0.7132 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 8.9205e-06 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 25.6364 - tp: 65.6364 - val_accuracy: 0.5732 - val_auc: 0.5275 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5520 - val_prc: 0.7130 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 7.4424e-06 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.1364 - tp: 62.1364 - val_accuracy: 0.5732 - val_auc: 0.5282 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5543 - val_prc: 0.7131 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 7.6963e-06 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 27.9091 - tp: 63.3636 - val_accuracy: 0.5732 - val_auc: 0.5288 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5573 - val_prc: 0.7135 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 7.5537e-06 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.5455 - tp: 61.7273 - val_accuracy: 0.5732 - val_auc: 0.5288 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5595 - val_prc: 0.7133 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 7.6034e-06 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 26.8182 - tp: 64.4545 - val_accuracy: 0.5732 - val_auc: 0.5292 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5614 - val_prc: 0.7136 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.0731e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.3636 - tp: 61.9091 - val_accuracy: 0.5732 - val_auc: 0.5292 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5640 - val_prc: 0.7136 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 1.0306e-05 - prc: 1.0000 - precision: 1.0000 - recall: 1.0000 - tn: 29.3182 - tp: 61.9545 - val_accuracy: 0.5732 - val_auc: 0.5285 - val_fn: 19.0000 - val_fp: 16.0000 - val_loss: 1.5656 - val_prc: 0.7132 - val_precision: 0.6981 - val_recall: 0.6607 - val_tn: 10.0000 - val_tp: 37.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2b57756a40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + \"scaled-cwt-mexh-cnn-3-no-ovr-60\" #datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# model.fit(train_ds, epochs=100, validation_data=test_ds, callbacks=[tensorboard_callback])\n",
    "model.fit(train_ds, epochs=100, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.export(\"../data/models/v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5718 - auc: 0.5099 - fn: 11.5833 - fp: 10.3333 - loss: 1.4425 - prc: 0.7167 - precision: 0.6890 - recall: 0.6899 - tn: 5.0000 - tp: 23.4167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5655936002731323,\n",
       " 37.0,\n",
       " 16.0,\n",
       " 10.0,\n",
       " 19.0,\n",
       " 0.5731707215309143,\n",
       " 0.698113203048706,\n",
       " 0.6607142686843872,\n",
       " 0.5285027027130127,\n",
       " 0.7132093906402588]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279ms/step\n",
      "MCC: 0.0\n",
      "Accuracy: 0.6829\n",
      "Precision: 0.6829\n",
      "Recall: 1.0\n",
      "F1: 0.8116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        26\n",
      "           1       0.68      1.00      0.81        56\n",
      "\n",
      "    accuracy                           0.68        82\n",
      "   macro avg       0.34      0.50      0.41        82\n",
      "weighted avg       0.47      0.68      0.55        82\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahmi/research/eegautism/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/fahmi/research/eegautism/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/fahmi/research/eegautism/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) > 0.5\n",
    "\n",
    "print(\"MCC:\", np.round(matthews_corrcoef(y_test, y_pred), 4))\n",
    "print(\"Accuracy:\", np.round(accuracy_score(y_test, y_pred), 4))\n",
    "print(\"Precision:\", np.round(precision_score(y_test, y_pred), 4))\n",
    "print(\"Recall:\", np.round(recall_score(y_test, y_pred), 4))\n",
    "print(\"F1:\", np.round(f1_score(y_test, y_pred), 4))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2ae8603e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANQAAADZCAYAAABYQB7GAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAY8UlEQVR4nO3de1hU5b4H8O9iYGZAxuGm4AhiNIqSBopJ7ryxN0q2t1puj2Z4RLx0slSCMHW3FdFtdLqoYZp5QcQwdZd6hMwyS8VLeRDxVALKRUVBhZDLgAww854/2I57InUGX1yz9Pd5nnke5501a74CX9asxVrzCowxBkIIF3ZiByDkYUKFIoQjKhQhHFGhCOGICkUIR1QoQjiiQhHCERWKEI7sxQ5wP4xGI0pLS6FSqSAIgthxyEOKMYba2lpoNBrY2d19GyTpQpWWlsLHx0fsGOQRUVJSAm9v77suI+lCqVQqAMBgPAd7OIicRjouxg8UO4KkGPUNuPjOMtPP291IulC33ubZwwH2AhXKUnZKpdgRJMmS3Qo6KEEIR1QoQjiiQhHCERWKEI6oUIRwRIUihCMqFCEcUaEI4YgKRQhHVChCOKJCEcIRFYoQjqhQhHBEhSKEIyoUIRxRoQjhiApFCEdUKEI4okIRwhEVihCOqFCEcESFIoQjKhQhHFGhCOGICkUIR1QoQjiiQhHCERWKEI6oUIRwRIUihCNJT2djq0ZPrcD4Wdfh1qkZRWcdsfbvXZGf4yR2LJvwX32zMdK3GI+pq6BvluF0uRfey3oaxTUuZssFdbqKmP4nEehxHUYmILfSA9MO/Bl6g23/yNrEFmrNmjXo3r07lEolQkJCcPLkSbEjtdmwMTfwcnwp0lZ44bXwnig6q8TybUVQuzeJHc0mPOVVhk/znsCEL19A1Dd/gb1gRPLIDDja3/76BHW6ik0j9uFYqQ/GfzkOf834Kz7NewJGZvvTvopeqB07diA2Nhbx8fHIzs5GYGAgwsPDcf36dbGjtcm4lyuwf5sbvtnhhkvnlUia7w39TQHhkyrFjmYTZhz4M3YX9EJBlRvybnhg/tFQdHXW4Qn3ctMyfxt4HKm5fbD+p34oqHJDcY0LvrqgRZNRJmJyy4heqBUrVmDmzJmIiopCQEAA1q1bBycnJyQnJ4sdzWr2Dkb0eLIe2Zm3p45kTMDpTBUCgutFTGa7VPJGAEC1vmVWRTflTQR1uo7Km47Y/txuHJ+4BZ8++z8I7lwmZkyLiVqoxsZGnDp1CmFhYaYxOzs7hIWF4cSJE62W1+v1qKmpMbvZko5uBsjsgapy8/f5Nyrs4dqpWaRUtksAw1sDj+HUNS+cr3IDAPioWr6ns4OysPNcb0w/8Gf88qsHtoSnw1dVJWJay4haqIqKChgMBnh6epqNe3p64urVq62WT0xMhFqtNt1oBnhpi386Ez1cK/H64X/7hQoGANhxLgC7Cnoht9IDif/7DIqqXTC+R75YUS0m+ls+ayxcuBDV1dWmW0lJidiRzNRUymBoBlx+szVy9WjGjXLbPjr1oC0OyUSoz0VM2T8G1+qdTePlN1uOhhZUuZotX1Ttii4dah9oxrYQtVAeHh6QyWS4du2a2fi1a9fg5eXVanmFQoGOHTua3WxJc5Mdzv+fE/oNvv2NFwSGoME6nD1Fh81bMCwOycSIbsWYsn80LuvMv4eXdSpcq3PCY+oqs/HuHatQWqeCrRO1UHK5HMHBwTh48KBpzGg04uDBgxg0aJCIydpu13oPjHqpEmH/UQkfbQPmvHMZSicjvtnuJnY0mxD/dCbGPH4esUfCUNcsh4djPTwc66GQ3dqqC9j4SxCm9P4Z4b6F6KaqRnS/k/BTV+Gf53uJmt0Sor8PiY2NRWRkJAYMGICBAwdi1apVqKurQ1RUlNjR2uTwXleo3Q2YMu8qXDs1o+gXR7wV8RiqKhzEjmYTInqdBQCkjdprNj7/6HDsLmgpzJazT0IhM+BvA49DLdcj74Y7or75C0pq1Q88r7VEL9TEiRNRXl6OxYsX4+rVqwgKCsL+/ftbHaiQkr2bPbB3s4fYMWxSz5RXLFpu/U/9sP6nfu2chj/RCwUAs2fPxuzZs8WOQch9s6hQe/fuvfdC/zJmzJg2hyFE6iwq1PPPP2/RygRBgMFguJ88hEiaRYUyGo3tnYOQh8J9HTZvaGjglYOQh4LVhTIYDFi2bBm6du0KZ2dnFBUVAQAWLVqETZs2cQ9IiJRYXajly5cjJSUF7777LuRyuWm8T58+2LhxI9dwhEiN1YVKTU3F+vXrERERAZns9vUpgYGByMvL4xqOEKmxulBXrlyBVqttNW40GtHURFelkkeb1YUKCAhAZmZmq/HPP/8c/fpJ7y/bhPBk9ZkSixcvRmRkJK5cuQKj0Yhdu3YhPz8fqampyMjIaI+MhEiG1VuosWPHIj09Hd9++y06dOiAxYsXIzc3F+np6RgxYkR7ZCREMtp0Lt+QIUNw4MAB3lkIkbw2nxyblZWF3NxcAC37VcHBwdxCESJVVhfq8uXLmDRpEo4dOwYXFxcAQFVVFf7whz9g+/bt8Pb25p2REMmweh9qxowZaGpqQm5uLiorK1FZWYnc3FwYjUbMmDGjPTISIhlWb6EOHz6M48ePw9/f3zTm7++P1atXY8iQIVzDESI1Vm+hfHx8fvcPuAaDARqNhksoQqTK6kK99957mDNnDrKyskxjWVlZiI6Oxvvvv881HCFSY9FbPldXVwjC7Q9qr6urQ0hICOztW57e3NwMe3t7TJs2zeKLEQl5GFlUqFWrVrVzDEIeDhYVKjIysr1zEPJQuK9PPWpoaEBjY6PZmK19mishD5LVByXq6uowe/ZsdO7cGR06dICrq6vZjZBHmdWFevPNN/Hdd9/h448/hkKhwMaNG5GQkACNRoPU1NT2yEiIZFj9li89PR2pqakYPnw4oqKiMGTIEGi1Wvj6+iItLQ0RERHtkZMQSbB6C1VZWQk/Pz8ALftLlZUtU10OHjwYR44c4ZuOEImxulB+fn4oLi4GAPTq1Qs7d+4E0LLlunWyLCGPKqsLFRUVhTNnzgAAFixYgDVr1kCpVCImJgbz5s3jHpAQKbF6HyomJsb077CwMOTl5eHUqVPQarV48sknuYYjRGrue/YNX19f+Pr68shCiORZVKikpCSLVzh37tw2hyFE6iwq1MqVKy1amSAIVCjySLOoULeO6pGHw7mpH4sdQVJqao1wTbBsWVEnrSbkYUOFIoQjKhQhHFGhCOGICkUIR20qVGZmJiZPnoxBgwbhypUrAICtW7fi6NGjXMMRIjVWF+qLL75AeHg4HB0dcfr0aej1egBAdXU13n77be4BCZESqwv1j3/8A+vWrcOGDRvg4OBgGn/mmWeQnZ3NNRwhUmN1ofLz8zF06NBW42q1GlVVVTwyESJZVhfKy8sLBQUFrcaPHj1quvCQkEeV1YWaOXMmoqOj8eOPP0IQBJSWliItLQ1xcXGYNWtWe2QkRDKsvnxjwYIFMBqN+NOf/oT6+noMHToUCoUCcXFxmDNnTntkJEQyBMYYa8sTGxsbUVBQAJ1Oh4CAADg7O/POdk81NTVQq9UYjrGwFxzu/QQCAPi6NEfsCJJSU2uEa88iVFdX3/NzJ9t8gaFcLkdAQEBbn07IQ8nqQoWGhppNHPBb33333X0FIkTKrC5UUFCQ2f2mpibk5OTg559/ps9AJ488qwt1p6t3lyxZAp1Od9+BCJEybifHTp48GcnJybxWR4gkcSvUiRMnoFQqea2OEEmy+i3fuHHjzO4zxlBWVoasrCwsWrSIWzBCpMjqQqnVarP7dnZ28Pf3x9KlSzFy5EhuwQiRIqsKZTAYEBUVhb59+9JcUIT8Dqv2oWQyGUaOHElnlRNyB1YflOjTpw+KioraIwshktemCwzj4uKQkZGBsrIy1NTUmN0IeZRZvA+1dOlSvPHGG3juuecAAGPGjDE7BYkxBkEQYDAY+KckRCIsLlRCQgJeeeUVfP/99+2ZhxBJs7hQt67yGDZsWLuFIUTqrNqHuttZ5oQQK/8O1bNnz3uW6tYk1oQ8iqwqVEJCQqszJQght1lVqBdffBGdO3duryyESJ7FhaL9J8uNnlqB8bOuw61TM4rOOmLt37siP8dJ7Fg2Yev7Xvh0hZfZmPfjDdiUmWe6fzbLCSn/3QV52U6QyQC/J27i7W2FUDi26eNPHiiLD0q08bNc7urIkSMYPXo0NBoNBEHAnj17uL/GgzZszA28HF+KtBVeeC28J4rOKrF8WxHU7k1iR7MZvv438VnOz6bbij3nTY+dzXLCWxGPI3hoLZL2nUfSvnMYE1UBQSLTWlgc02g0cn+7V1dXh8DAQKxZs4bresU07uUK7N/mhm92uOHSeSWS5ntDf1NA+CQ6WHOLTAa4dW423dTut08G+GRJVzw/vRwT51xHd/8G+Gj1GDamCnKF7W+dgPv41CMeRo0ahVGjRokZgSt7ByN6PFmP7R/d/sXDmIDTmSoEBNeLmMy2XCmWY1K/JyBXGNE7uA7TFpahs3cTqirskZfdAX984QZeH90DZRfl8NHqMXV+GfqE1Ikd2yIS2ZC20Ov1Nn3uYEc3A2T2QFW5+e+pGxX2cO3ULFIq29Krfx3iVl3C8rRCzHnnMq5eUuCNF3qgXmeHsotyAMDWFV4YFfErlqcVQdu3HgsmPo4rRXKRk1tG1C2UtRITE5GQYOF03MQmPfXHWtO//QIa0KtfPf5zYACO7HWBT48GAMBzk39F+Istb5G1fW8i56gKX293x7S/lYmS2RqS2kItXLgQ1dXVpltJSYnYkczUVMpgaAZcfrM1cvVoxo1ySf3uemCc1QZ4++lRekEBd8+Wr5tvzwazZXy0Dbh+RRqfDCypQikUCnTs2NHsZkuam+xw/v+c0G/w7d/CgsAQNFiHs6fosPnvuVlnh9KLcrh1boKnTyPcvRpxuVBhtsyVIgU6e0vjKCn92uRs13oPxK0qwbkzTsg/7YQXZpZD6WTEN9vdxI5mE9YnaPD0yGp09m7Cr1ftsfX9LpDZAcNfuAFBAMbPKsfW973gF3ATfk/cxLf/dENJoRJ/33BB7OgWEbVQOp3ObK6p4uJi5OTkwM3NDd26dRMxWdsd3usKtbsBU+ZdhWunZhT94oi3Ih5DVYU03rK0t4oyByS+2h21N2RQuzfjiafqsCrjHFz+deh83MxyNDUIWBffFbVVMvgFNCDxs0JoujeKnNwybZ59g4dDhw4hNDS01XhkZCRSUlLu+XyafaNtaPYN6zyQ2Td4GD58eLucgUGIWCR1UIIQW0eFIoQjKhQhHFGhCOGICkUIR1QoQjiiQhHCERWKEI6oUIRwRIUihCMqFCEcUaEI4YgKRQhHVChCOKJCEcIRFYoQjqhQhHBEhSKEIyoUIRxRoQjhiApFCEdUKEI4okIRwhEVihCOqFCEcESFIoQjKhQhHFGhCOGICkUIR1QoQjiiQhHCkaSnBL01t1QzmgCaZspiNbVGsSNISo2u5etlyVxmki5UbW3L5NBHsU/kJNLi2lPsBNJUW1sLtVp912VEnRL0fhmNRpSWlkKlUkEQBLHjmKmpqYGPjw9KSkpsbrZ6W2WrXzPGGGpra6HRaGBnd/e9JElvoezs7ODt7S12jLvq2LGjTf1wSIEtfs3utWW6hQ5KEMIRFYoQjqhQ7UShUCA+Ph4KhULsKJLxMHzNJH1QghBbQ1soQjiiQhHCERWKEI6oUIRwRIVqB2vWrEH37t2hVCoREhKCkydPih3Jph05cgSjR4+GRqOBIAjYs2eP2JHajArF2Y4dOxAbG4v4+HhkZ2cjMDAQ4eHhuH79utjRbFZdXR0CAwOxZs0asaPcNzpszllISAieeuopfPTRRwBazjf08fHBnDlzsGDBApHT2T5BELB79248//zzYkdpE9pCcdTY2IhTp04hLCzMNGZnZ4ewsDCcOHFCxGTkQaFCcVRRUQGDwQBPT0+zcU9PT1y9elWkVORBokIRwhEViiMPDw/IZDJcu3bNbPzatWvw8vISKRV5kKhQHMnlcgQHB+PgwYOmMaPRiIMHD2LQoEEiJiMPiqQvMLRFsbGxiIyMxIABAzBw4ECsWrUKdXV1iIqKEjuazdLpdCgoKDDdLy4uRk5ODtzc3NCtWzcRk7UBI9ytXr2adevWjcnlcjZw4ED2ww8/iB3Jpn3//fcMLR+zY3aLjIwUO5rV6O9QhHBE+1CEcESFIoQjKhQhHFGhCOGICkUIR1QoQjiiQhHCERXKBk2dOtXseqDhw4fj9ddff+A5Dh06BEEQUFVVdcdlrL3CdsmSJQgKCrqvXBcuXIAgCMjJybmv9bQHKpSFpk6dCkEQIAgC5HI5tFotli5diubm5nZ/7V27dmHZsmUWLWtJCUj7oXP5rPDss89i8+bN0Ov12LdvH1577TU4ODhg4cKFrZZtbGyEXC7n8rpubm5c1kPaH22hrKBQKODl5QVfX1/MmjULYWFh2Lt3L4Dbb9OWL18OjUYDf39/AEBJSQkmTJgAFxcXuLm5YezYsbhw4YJpnQaDAbGxsXBxcYG7uzvefPPNVhN7/fYtn16vx/z58+Hj4wOFQgGtVotNmzbhwoULCA0NBQC4urpCEARMnToVQMtZ74mJiXjsscfg6OiIwMBAfP7552avs2/fPvTs2ROOjo4IDQ01y2mp+fPno2fPnnBycoKfnx8WLVqEpqamVst98skn8PHxgZOTEyZMmIDq6mqzxzdu3IjevXtDqVSiV69eWLt2rdVZxECFug+Ojo5obGw03T948CDy8/Nx4MABZGRkoKmpCeHh4VCpVMjMzMSxY8fg7OyMZ5991vS8Dz74ACkpKUhOTsbRo0dRWVmJ3bt33/V1p0yZgs8++wxJSUnIzc3FJ598AmdnZ/j4+OCLL74AAOTn56OsrAwffvghACAxMRGpqalYt24dfvnlF8TExGDy5Mk4fPgwgJbijxs3DqNHj0ZOTg5mzJjRps/AUKlUSElJwdmzZ/Hhhx9iw4YNWLlypdkyBQUF2LlzJ9LT07F//36cPn0ar776qunxtLQ0LF68GMuXL0dubi7efvttLFq0CFu2bLE6zwMn8sm5khEZGcnGjh3LGGPMaDSyAwcOMIVCweLi4kyPe3p6Mr1eb3rO1q1bmb+/PzMajaYxvV7PHB0d2ddff80YY6xLly7s3XffNT3e1NTEvL29Ta/FGGPDhg1j0dHRjDHG8vPzGQB24MCB381568ztGzdumMYaGhqYk5MTO378uNmy06dPZ5MmTWKMMbZw4UIWEBBg9vj8+fNbreu3ALDdu3ff8fH33nuPBQcHm+7Hx8czmUzGLl++bBr76quvmJ2dHSsrK2OMMfb444+zbdu2ma1n2bJlbNCgQYwxxoqLixkAdvr06Tu+rlhoH8oKGRkZcHZ2RlNTE4xGI1566SUsWbLE9Hjfvn3N9pvOnDmDgoICqFQqs/U0NDSgsLAQ1dXVKCsrQ0hIiOkxe3t7DBgw4I7zuebk5EAmk2HYsGEW5y4oKEB9fT1GjBhhNt7Y2Ih+/foBAHJzc81yAGjTRZE7duxAUlISCgsLodPp0Nzc3GrytG7duqFr165mr2M0GpGfnw+VSoXCwkJMnz4dM2fONC3T3Nxs8aRnYqJCWSE0NBQff/wx5HI5NBoN7O3Nv3wdOnQwu6/T6RAcHIy0tLRW6+rUqVObMjg6Olr9HJ1OBwD48ssvzX6QAXCdOubEiROIiIhAQkICwsPDoVarsX37dnzwwQdWZ92wYUOrgstkMm5Z2wsVygodOnSAVqu1ePn+/ftjx44d6Ny58x2nuOzSpQt+/PFHDB06FEDLb+JTp06hf//+v7t83759YTQacfjwYbOPK7vl1hbSYDCYxgICAqBQKHDp0qU7btl69+5tOsByyw8//HDv/+S/OX78OHx9ffHWW2+Zxi5evNhquUuXLqG0tBQajcb0OnZ2dvD394enpyc0Gg2KiooQERFh1evbAjoo0Y4iIiLg4eGBsWPHIjMzE8XFxTh06BDmzp2Ly5cvAwCio6PxzjvvYM+ePcjLy8Orr756178hde/eHZGRkZg2bRr27NljWufOnTsBAL6+vhAEARkZGSgvL4dOp4NKpUJcXBxiYmKwZcsWFBYWIjs7G6tXrzbt6L/yyis4f/485s2bh/z8fGzbtg0pKSlW/X979OiBS5cuYfv27SgsLERSUtLvHmBRKpWIjIzEmTNnkJmZiblz52LChAmmD7JJSEhAYmIikpKScO7cOfz000/YvHkzVqxYYVUeUYi9EycV/35QwprHy8rK2JQpU5iHhwdTKBTMz8+PzZw5k1VXVzPGWg5CREdHs44dOzIXFxcWGxvLpkyZcseDEowxdvPmTRYTE8O6dOnC5HI502q1LDk52fT40qVLmZeXFxMEwXQZudFoZKtWrWL+/v7MwcGBderUiYWHh7PDhw+bnpeens60Wi1TKBRsyJAhLDk52eqDEvPmzWPu7u7M2dmZTZw4ka1cuZKp1WrT4/Hx8SwwMJCtXbuWaTQaplQq2fjx41llZaXZetPS0lhQUBCTy+XM1dWVDR06lO3atYsxZtsHJegSeEI4ord8hHBEhSKEIyoUIRxRoQjhiApFCEdUKEI4okIRwhEVihCOqFCEcESFIoQjKhQhHFGhCOHo/wEjQxVWSeD7qQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
