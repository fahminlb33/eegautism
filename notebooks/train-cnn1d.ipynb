{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "html[data-theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 220MB\n",
       "Dimensions:           (samples: 670, time_steps: 2560, channels: 16)\n",
       "Coordinates:\n",
       "  * samples           (samples) int64 5kB 0 1 2 3 4 5 ... 665 666 667 668 669\n",
       "Dimensions without coordinates: time_steps, channels\n",
       "Data variables:\n",
       "    signal            (samples, time_steps, channels) float64 220MB ...\n",
       "    label             (samples) int64 5kB ...\n",
       "    segment           (samples) int64 5kB ...\n",
       "    patient_name      (samples) &lt;U8 21kB ...\n",
       "    recording_number  (samples) int64 5kB ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-55302c56-e2e6-4b5f-88e5-e357442e5655' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-55302c56-e2e6-4b5f-88e5-e357442e5655' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>samples</span>: 670</li><li><span>time_steps</span>: 2560</li><li><span>channels</span>: 16</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-0a229fa1-adb0-4f38-9b4d-cee9616e68b9' class='xr-section-summary-in' type='checkbox'  checked><label for='section-0a229fa1-adb0-4f38-9b4d-cee9616e68b9' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>samples</span></div><div class='xr-var-dims'>(samples)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 5 ... 665 666 667 668 669</div><input id='attrs-053ecf65-940a-4fb6-9ca3-a80ac7b9c099' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-053ecf65-940a-4fb6-9ca3-a80ac7b9c099' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ce820cb8-4175-45cd-8927-b44cfd0b7943' class='xr-var-data-in' type='checkbox'><label for='data-ce820cb8-4175-45cd-8927-b44cfd0b7943' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  0,   1,   2, ..., 667, 668, 669])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f5aa83c7-f4e8-48f9-851d-b7236c010048' class='xr-section-summary-in' type='checkbox'  checked><label for='section-f5aa83c7-f4e8-48f9-851d-b7236c010048' class='xr-section-summary' >Data variables: <span>(5)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>signal</span></div><div class='xr-var-dims'>(samples, time_steps, channels)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-033244ed-cf90-4fea-a950-d7d664bd20bc' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-033244ed-cf90-4fea-a950-d7d664bd20bc' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f50ace33-e994-491c-8ffd-2a506db9bc97' class='xr-var-data-in' type='checkbox'><label for='data-f50ace33-e994-491c-8ffd-2a506db9bc97' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[27443200 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>label</span></div><div class='xr-var-dims'>(samples)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-425d675e-4cca-4fb7-89d9-d7e927c10c8c' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-425d675e-4cca-4fb7-89d9-d7e927c10c8c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1abea190-02b2-4bd4-83c7-44f518ba992b' class='xr-var-data-in' type='checkbox'><label for='data-1abea190-02b2-4bd4-83c7-44f518ba992b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[670 values with dtype=int64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>segment</span></div><div class='xr-var-dims'>(samples)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-b792831e-0729-4ff1-a388-fdfbc22b2766' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b792831e-0729-4ff1-a388-fdfbc22b2766' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f30d2856-d90e-40f8-84dd-9a2eef20ed74' class='xr-var-data-in' type='checkbox'><label for='data-f30d2856-d90e-40f8-84dd-9a2eef20ed74' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[670 values with dtype=int64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>patient_name</span></div><div class='xr-var-dims'>(samples)</div><div class='xr-var-dtype'>&lt;U8</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-414b5255-d97d-4be2-96db-27699794ab10' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-414b5255-d97d-4be2-96db-27699794ab10' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b1ecc460-81da-4bb6-8c0d-443bd43372e9' class='xr-var-data-in' type='checkbox'><label for='data-b1ecc460-81da-4bb6-8c0d-443bd43372e9' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[670 values with dtype=&lt;U8]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>recording_number</span></div><div class='xr-var-dims'>(samples)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-ea47c1ea-7550-4b44-b8ea-47cfe24491b7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ea47c1ea-7550-4b44-b8ea-47cfe24491b7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e793af56-db79-4b6e-bddc-301b96be019f' class='xr-var-data-in' type='checkbox'><label for='data-e793af56-db79-4b6e-bddc-301b96be019f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[670 values with dtype=int64]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-65f6df04-1c2f-43fc-8e61-941e6b9ab256' class='xr-section-summary-in' type='checkbox'  ><label for='section-65f6df04-1c2f-43fc-8e61-941e6b9ab256' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>samples</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-ce1cc9c1-e3bf-4c34-b83d-c701798a6a1a' class='xr-index-data-in' type='checkbox'/><label for='index-ce1cc9c1-e3bf-4c34-b83d-c701798a6a1a' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "       ...\n",
       "       660, 661, 662, 663, 664, 665, 666, 667, 668, 669],\n",
       "      dtype=&#x27;int64&#x27;, name=&#x27;samples&#x27;, length=670))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-1176689e-5b41-4b4a-8d57-ce3c8383b407' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-1176689e-5b41-4b4a-8d57-ce3c8383b407' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 220MB\n",
       "Dimensions:           (samples: 670, time_steps: 2560, channels: 16)\n",
       "Coordinates:\n",
       "  * samples           (samples) int64 5kB 0 1 2 3 4 5 ... 665 666 667 668 669\n",
       "Dimensions without coordinates: time_steps, channels\n",
       "Data variables:\n",
       "    signal            (samples, time_steps, channels) float64 220MB ...\n",
       "    label             (samples) int64 5kB ...\n",
       "    segment           (samples) int64 5kB ...\n",
       "    patient_name      (samples) <U8 21kB ...\n",
       "    recording_number  (samples) int64 5kB ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = xr.open_dataset(\"../data/data_10.nc\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  patient_name\n",
       "0      amer            85\n",
       "       dhelal          84\n",
       "       mahmud          44\n",
       "       omran           64\n",
       "1      bader           64\n",
       "       mohammed        99\n",
       "       nour            71\n",
       "       saud            46\n",
       "       shahad          38\n",
       "       yahia           75\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sample index\n",
    "df = dataset[[\"label\", \"patient_name\", \"samples\"]].to_dataframe()\n",
    "df.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- SAMPLING METHOD 1\n",
    "test_patients = [\n",
    "    # autism\n",
    "\n",
    "    # normal\n",
    "\n",
    "]\n",
    "\n",
    "# split train and test persons\n",
    "test_dataset = dataset.sel(\n",
    "    samples=df[df[\"patient_names\"].isin(test_patients)].index.tolist()\n",
    ")\n",
    "train_dataset = dataset.sel(\n",
    "    samples=df[~df[\"patient_names\"].isin(test_patients)].index.tolist()\n",
    ")\n",
    "\n",
    "# get Xy for train\n",
    "X_train = train_dataset[\"signal\"].to_numpy()\n",
    "y_train = train_dataset[\"label\"].to_numpy()\n",
    "\n",
    "# get Xy for test\n",
    "X_test = test_dataset[\"signal\"].to_numpy()\n",
    "y_test = test_dataset[\"label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---- SAMPLING METHOD 2\n",
    "# get Xy\n",
    "X = dataset[\"signal\"].to_numpy()\n",
    "y = dataset[\"label\"].to_numpy()\n",
    "\n",
    "# stratified random sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (448, 2560, 16) (448,)\n",
      "Classdist: (array([0, 1]), array([185, 263]))\n",
      "Test: (222, 2560, 16) (222,)\n",
      "Classdist: (array([0, 1]), array([ 92, 130]))\n"
     ]
    }
   ],
   "source": [
    "# print statistics\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Classdist:\", np.unique(y_train, return_counts=True))\n",
    "\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n",
    "print(\"Classdist:\", np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 1D Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 10:50:58.205570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-03 10:50:58.280420: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-03 10:50:58.302333: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-03 10:50:58.444472: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-03 10:50:59.614633: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725335861.034796   31904 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725335861.196759   31904 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725335861.196807   31904 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725335861.199439   31904 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725335861.199512   31904 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725335861.199541   31904 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725335861.407468   31904 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725335861.407545   31904 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-03 10:57:41.407556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1725335861.407609   31904 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-03 10:57:41.408311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1277</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1277\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m33,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,025\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,913</span> (152.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,913\u001b[0m (152.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,913</span> (152.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,913\u001b[0m (152.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2],))\n",
    "\n",
    "x = tf.keras.layers.Conv1D(32, kernel_size=8, strides=2, activation=\"relu\", use_bias=False)(inputs)\n",
    "# x = tf.keras.layers.Conv1D(32, kernel_size=6, strides=2, activation=\"relu\", use_bias=False)(inputs)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    # loss=tf.keras.losses.BinaryFocalCrossentropy(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "    #   tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725335892.306944   33537 service.cc:146] XLA service 0x7f02d802a8e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1725335892.306979   33537 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-09-03 10:58:12.370470: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-03 10:58:12.530635: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/28\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5563 - auc: 0.5613 - fn: 29.5333 - fp: 27.5333 - loss: 1.5089 - precision: 0.6319 - recall: 0.6210 - tn: 25.5333 - tp: 45.4000      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725335895.068172   33537 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 101ms/step - accuracy: 0.5748 - auc: 0.5832 - fn: 47.0345 - fp: 52.2069 - loss: 1.3286 - precision: 0.6395 - recall: 0.6526 - tn: 46.2414 - tp: 93.9655 - val_accuracy: 0.6712 - val_auc: 0.7280 - val_fn: 14.0000 - val_fp: 59.0000 - val_loss: 0.6090 - val_precision: 0.6629 - val_recall: 0.8923 - val_tn: 33.0000 - val_tp: 116.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6877 - auc: 0.7941 - fn: 27.5862 - fp: 44.8276 - loss: 0.5319 - precision: 0.7069 - recall: 0.7712 - tn: 55.5172 - tp: 111.5172 - val_accuracy: 0.6982 - val_auc: 0.8370 - val_fn: 1.0000 - val_fp: 66.0000 - val_loss: 0.5740 - val_precision: 0.6615 - val_recall: 0.9923 - val_tn: 26.0000 - val_tp: 129.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6960 - auc: 0.8019 - fn: 19.3103 - fp: 47.3793 - loss: 0.5391 - precision: 0.6944 - recall: 0.8761 - tn: 51.1724 - tp: 121.5862 - val_accuracy: 0.6892 - val_auc: 0.8062 - val_fn: 58.0000 - val_fp: 11.0000 - val_loss: 0.7068 - val_precision: 0.8675 - val_recall: 0.5538 - val_tn: 81.0000 - val_tp: 72.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7340 - auc: 0.8287 - fn: 25.6552 - fp: 34.4828 - loss: 0.5404 - precision: 0.7795 - recall: 0.7609 - tn: 64.5517 - tp: 114.7586 - val_accuracy: 0.7252 - val_auc: 0.8190 - val_fn: 47.0000 - val_fp: 14.0000 - val_loss: 0.6352 - val_precision: 0.8557 - val_recall: 0.6385 - val_tn: 78.0000 - val_tp: 83.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8278 - auc: 0.9228 - fn: 16.2069 - fp: 24.6552 - loss: 0.3671 - precision: 0.8259 - recall: 0.8833 - tn: 75.1379 - tp: 123.4483 - val_accuracy: 0.7748 - val_auc: 0.8803 - val_fn: 16.0000 - val_fp: 34.0000 - val_loss: 0.5227 - val_precision: 0.7703 - val_recall: 0.8769 - val_tn: 58.0000 - val_tp: 114.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8329 - auc: 0.9259 - fn: 17.9655 - fp: 20.9310 - loss: 0.3398 - precision: 0.8472 - recall: 0.8662 - tn: 77.8966 - tp: 122.6552 - val_accuracy: 0.8108 - val_auc: 0.9033 - val_fn: 14.0000 - val_fp: 28.0000 - val_loss: 0.4937 - val_precision: 0.8056 - val_recall: 0.8923 - val_tn: 64.0000 - val_tp: 116.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8695 - auc: 0.9562 - fn: 9.8966 - fp: 23.0690 - loss: 0.2882 - precision: 0.8507 - recall: 0.9449 - tn: 74.3448 - tp: 132.1379 - val_accuracy: 0.8288 - val_auc: 0.9115 - val_fn: 7.0000 - val_fp: 31.0000 - val_loss: 0.4730 - val_precision: 0.7987 - val_recall: 0.9462 - val_tn: 61.0000 - val_tp: 123.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8278 - auc: 0.9308 - fn: 10.7241 - fp: 28.0000 - loss: 0.3759 - precision: 0.8022 - recall: 0.9396 - tn: 72.8966 - tp: 127.8276 - val_accuracy: 0.7658 - val_auc: 0.8567 - val_fn: 14.0000 - val_fp: 38.0000 - val_loss: 0.5131 - val_precision: 0.7532 - val_recall: 0.8923 - val_tn: 54.0000 - val_tp: 116.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7591 - auc: 0.8624 - fn: 19.9655 - fp: 35.7586 - loss: 0.4965 - precision: 0.7504 - recall: 0.8772 - tn: 66.4483 - tp: 117.2759 - val_accuracy: 0.8018 - val_auc: 0.8978 - val_fn: 13.0000 - val_fp: 31.0000 - val_loss: 0.5171 - val_precision: 0.7905 - val_recall: 0.9000 - val_tn: 61.0000 - val_tp: 117.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8919 - auc: 0.9547 - fn: 7.9310 - fp: 17.6207 - loss: 0.3057 - precision: 0.8675 - recall: 0.9490 - tn: 86.8966 - tp: 127.0000 - val_accuracy: 0.8153 - val_auc: 0.8925 - val_fn: 23.0000 - val_fp: 18.0000 - val_loss: 0.5089 - val_precision: 0.8560 - val_recall: 0.8231 - val_tn: 74.0000 - val_tp: 107.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9059 - auc: 0.9666 - fn: 8.5517 - fp: 13.4828 - loss: 0.2364 - precision: 0.9112 - recall: 0.9280 - tn: 87.0000 - tp: 130.4138 - val_accuracy: 0.8378 - val_auc: 0.9021 - val_fn: 30.0000 - val_fp: 6.0000 - val_loss: 0.6031 - val_precision: 0.9434 - val_recall: 0.7692 - val_tn: 86.0000 - val_tp: 100.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9161 - auc: 0.9724 - fn: 10.8621 - fp: 8.3448 - loss: 0.2270 - precision: 0.9429 - recall: 0.9081 - tn: 94.6207 - tp: 125.6207 - val_accuracy: 0.7793 - val_auc: 0.9013 - val_fn: 44.0000 - val_fp: 5.0000 - val_loss: 0.7607 - val_precision: 0.9451 - val_recall: 0.6615 - val_tn: 87.0000 - val_tp: 86.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8865 - auc: 0.9538 - fn: 10.6552 - fp: 14.6897 - loss: 0.2814 - precision: 0.8995 - recall: 0.9107 - tn: 83.4483 - tp: 130.6552 - val_accuracy: 0.7387 - val_auc: 0.9038 - val_fn: 56.0000 - val_fp: 2.0000 - val_loss: 0.9266 - val_precision: 0.9737 - val_recall: 0.5692 - val_tn: 90.0000 - val_tp: 74.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8834 - auc: 0.9717 - fn: 11.9310 - fp: 10.8276 - loss: 0.2366 - precision: 0.9239 - recall: 0.8861 - tn: 85.2069 - tp: 131.4828 - val_accuracy: 0.8604 - val_auc: 0.9253 - val_fn: 18.0000 - val_fp: 13.0000 - val_loss: 0.5192 - val_precision: 0.8960 - val_recall: 0.8615 - val_tn: 79.0000 - val_tp: 112.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9372 - auc: 0.9866 - fn: 8.0690 - fp: 6.3103 - loss: 0.1542 - precision: 0.9580 - recall: 0.9423 - tn: 86.3448 - tp: 138.7241 - val_accuracy: 0.8649 - val_auc: 0.9313 - val_fn: 24.0000 - val_fp: 6.0000 - val_loss: 0.5265 - val_precision: 0.9464 - val_recall: 0.8154 - val_tn: 86.0000 - val_tp: 106.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9596 - auc: 0.9926 - fn: 5.5172 - fp: 5.3103 - loss: 0.1272 - precision: 0.9722 - recall: 0.9620 - tn: 88.5172 - tp: 140.1035 - val_accuracy: 0.8694 - val_auc: 0.9348 - val_fn: 19.0000 - val_fp: 10.0000 - val_loss: 0.5379 - val_precision: 0.9174 - val_recall: 0.8538 - val_tn: 82.0000 - val_tp: 111.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9672 - auc: 0.9932 - fn: 3.2759 - fp: 5.1724 - loss: 0.1243 - precision: 0.9635 - recall: 0.9826 - tn: 92.3103 - tp: 138.6897 - val_accuracy: 0.8739 - val_auc: 0.9305 - val_fn: 18.0000 - val_fp: 10.0000 - val_loss: 0.5567 - val_precision: 0.9180 - val_recall: 0.8615 - val_tn: 82.0000 - val_tp: 112.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9589 - auc: 0.9924 - fn: 7.3103 - fp: 3.0000 - loss: 0.1209 - precision: 0.9840 - recall: 0.9489 - tn: 90.9655 - tp: 138.1724 - val_accuracy: 0.8604 - val_auc: 0.9244 - val_fn: 12.0000 - val_fp: 19.0000 - val_loss: 0.5064 - val_precision: 0.8613 - val_recall: 0.9077 - val_tn: 73.0000 - val_tp: 118.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9272 - auc: 0.9856 - fn: 6.5172 - fp: 9.5172 - loss: 0.1561 - precision: 0.9262 - recall: 0.9544 - tn: 88.7931 - tp: 134.6207 - val_accuracy: 0.8919 - val_auc: 0.9344 - val_fn: 14.0000 - val_fp: 10.0000 - val_loss: 0.4876 - val_precision: 0.9206 - val_recall: 0.8923 - val_tn: 82.0000 - val_tp: 116.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9432 - auc: 0.9908 - fn: 5.9310 - fp: 9.0345 - loss: 0.1304 - precision: 0.9440 - recall: 0.9600 - tn: 90.0000 - tp: 134.4828 - val_accuracy: 0.8694 - val_auc: 0.9334 - val_fn: 10.0000 - val_fp: 19.0000 - val_loss: 0.4219 - val_precision: 0.8633 - val_recall: 0.9231 - val_tn: 73.0000 - val_tp: 120.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9293 - auc: 0.9783 - fn: 8.8966 - fp: 10.4483 - loss: 0.1842 - precision: 0.9355 - recall: 0.9482 - tn: 86.0690 - tp: 134.0345 - val_accuracy: 0.7613 - val_auc: 0.9128 - val_fn: 6.0000 - val_fp: 47.0000 - val_loss: 0.7503 - val_precision: 0.7251 - val_recall: 0.9538 - val_tn: 45.0000 - val_tp: 124.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7954 - auc: 0.8914 - fn: 23.5862 - fp: 20.9310 - loss: 0.5832 - precision: 0.8166 - recall: 0.8254 - tn: 81.4138 - tp: 113.5172 - val_accuracy: 0.8063 - val_auc: 0.9346 - val_fn: 7.0000 - val_fp: 36.0000 - val_loss: 0.6019 - val_precision: 0.7736 - val_recall: 0.9462 - val_tn: 56.0000 - val_tp: 123.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9338 - auc: 0.9824 - fn: 6.9655 - fp: 7.2069 - loss: 0.1824 - precision: 0.9304 - recall: 0.9545 - tn: 93.2414 - tp: 132.0345 - val_accuracy: 0.8604 - val_auc: 0.9291 - val_fn: 27.0000 - val_fp: 4.0000 - val_loss: 0.5496 - val_precision: 0.9626 - val_recall: 0.7923 - val_tn: 88.0000 - val_tp: 103.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9366 - auc: 0.9825 - fn: 8.5172 - fp: 6.9310 - loss: 0.1598 - precision: 0.9531 - recall: 0.9391 - tn: 90.7586 - tp: 133.2414 - val_accuracy: 0.8694 - val_auc: 0.9378 - val_fn: 25.0000 - val_fp: 4.0000 - val_loss: 0.5487 - val_precision: 0.9633 - val_recall: 0.8077 - val_tn: 88.0000 - val_tp: 105.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9397 - auc: 0.9865 - fn: 8.6552 - fp: 7.5517 - loss: 0.1473 - precision: 0.9559 - recall: 0.9444 - tn: 87.4828 - tp: 135.7586 - val_accuracy: 0.7748 - val_auc: 0.9286 - val_fn: 49.0000 - val_fp: 1.0000 - val_loss: 0.8883 - val_precision: 0.9878 - val_recall: 0.6231 - val_tn: 91.0000 - val_tp: 81.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9549 - auc: 0.9923 - fn: 4.1724 - fp: 7.0345 - loss: 0.1233 - precision: 0.9580 - recall: 0.9679 - tn: 89.2759 - tp: 138.9655 - val_accuracy: 0.8604 - val_auc: 0.9395 - val_fn: 28.0000 - val_fp: 3.0000 - val_loss: 0.5131 - val_precision: 0.9714 - val_recall: 0.7846 - val_tn: 89.0000 - val_tp: 102.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9749 - auc: 0.9965 - fn: 3.8966 - fp: 2.5172 - loss: 0.0918 - precision: 0.9873 - recall: 0.9705 - tn: 93.8966 - tp: 139.1379 - val_accuracy: 0.9009 - val_auc: 0.9467 - val_fn: 6.0000 - val_fp: 16.0000 - val_loss: 0.3782 - val_precision: 0.8857 - val_recall: 0.9538 - val_tn: 76.0000 - val_tp: 124.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9690 - auc: 0.9961 - fn: 2.5862 - fp: 5.2759 - loss: 0.0992 - precision: 0.9620 - recall: 0.9858 - tn: 95.6207 - tp: 135.9655 - val_accuracy: 0.8423 - val_auc: 0.9144 - val_fn: 11.0000 - val_fp: 24.0000 - val_loss: 0.5873 - val_precision: 0.8322 - val_recall: 0.9154 - val_tn: 68.0000 - val_tp: 119.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9106 - auc: 0.9798 - fn: 8.1379 - fp: 10.7586 - loss: 0.1881 - precision: 0.9029 - recall: 0.9364 - tn: 96.0000 - tp: 124.5517 - val_accuracy: 0.9099 - val_auc: 0.9531 - val_fn: 5.0000 - val_fp: 15.0000 - val_loss: 0.3172 - val_precision: 0.8929 - val_recall: 0.9615 - val_tn: 77.0000 - val_tp: 125.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9478 - auc: 0.9903 - fn: 5.4138 - fp: 7.0690 - loss: 0.1288 - precision: 0.9462 - recall: 0.9667 - tn: 91.8276 - tp: 135.1379 - val_accuracy: 0.9009 - val_auc: 0.9467 - val_fn: 12.0000 - val_fp: 10.0000 - val_loss: 0.5697 - val_precision: 0.9219 - val_recall: 0.9077 - val_tn: 82.0000 - val_tp: 118.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9643 - auc: 0.9946 - fn: 3.8966 - fp: 5.4828 - loss: 0.0932 - precision: 0.9613 - recall: 0.9781 - tn: 93.5862 - tp: 136.4828 - val_accuracy: 0.8829 - val_auc: 0.9500 - val_fn: 17.0000 - val_fp: 9.0000 - val_loss: 0.5524 - val_precision: 0.9262 - val_recall: 0.8692 - val_tn: 83.0000 - val_tp: 113.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9316 - auc: 0.9848 - fn: 9.0000 - fp: 8.2759 - loss: 0.1604 - precision: 0.9412 - recall: 0.9457 - tn: 87.2759 - tp: 134.8965 - val_accuracy: 0.8739 - val_auc: 0.9380 - val_fn: 23.0000 - val_fp: 5.0000 - val_loss: 0.6631 - val_precision: 0.9554 - val_recall: 0.8231 - val_tn: 87.0000 - val_tp: 107.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9494 - auc: 0.9913 - fn: 6.5517 - fp: 6.5172 - loss: 0.1230 - precision: 0.9592 - recall: 0.9534 - tn: 94.1724 - tp: 132.2069 - val_accuracy: 0.8604 - val_auc: 0.9355 - val_fn: 28.0000 - val_fp: 3.0000 - val_loss: 0.6951 - val_precision: 0.9714 - val_recall: 0.7846 - val_tn: 89.0000 - val_tp: 102.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9763 - auc: 0.9967 - fn: 3.1034 - fp: 3.6897 - loss: 0.0786 - precision: 0.9780 - recall: 0.9802 - tn: 99.4138 - tp: 133.2414 - val_accuracy: 0.8874 - val_auc: 0.9520 - val_fn: 5.0000 - val_fp: 20.0000 - val_loss: 0.5132 - val_precision: 0.8621 - val_recall: 0.9615 - val_tn: 72.0000 - val_tp: 125.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9461 - auc: 0.9776 - fn: 4.9310 - fp: 7.3103 - loss: 0.1730 - precision: 0.9413 - recall: 0.9661 - tn: 93.2069 - tp: 134.0000 - val_accuracy: 0.8514 - val_auc: 0.9321 - val_fn: 32.0000 - val_fp: 1.0000 - val_loss: 0.9009 - val_precision: 0.9899 - val_recall: 0.7538 - val_tn: 91.0000 - val_tp: 98.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9658 - auc: 0.9970 - fn: 4.1034 - fp: 3.2069 - loss: 0.0887 - precision: 0.9799 - recall: 0.9600 - tn: 101.9310 - tp: 130.2069 - val_accuracy: 0.8108 - val_auc: 0.9401 - val_fn: 6.0000 - val_fp: 36.0000 - val_loss: 0.7373 - val_precision: 0.7750 - val_recall: 0.9538 - val_tn: 56.0000 - val_tp: 124.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9303 - auc: 0.9863 - fn: 8.7586 - fp: 8.4483 - loss: 0.1533 - precision: 0.9364 - recall: 0.9436 - tn: 93.1379 - tp: 129.1035 - val_accuracy: 0.8694 - val_auc: 0.9333 - val_fn: 27.0000 - val_fp: 2.0000 - val_loss: 0.8515 - val_precision: 0.9810 - val_recall: 0.7923 - val_tn: 90.0000 - val_tp: 103.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9705 - auc: 0.9977 - fn: 3.4828 - fp: 3.6552 - loss: 0.0713 - precision: 0.9770 - recall: 0.9703 - tn: 99.8966 - tp: 132.4138 - val_accuracy: 0.8874 - val_auc: 0.9446 - val_fn: 19.0000 - val_fp: 6.0000 - val_loss: 0.6538 - val_precision: 0.9487 - val_recall: 0.8538 - val_tn: 86.0000 - val_tp: 111.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9586 - auc: 0.9934 - fn: 6.6552 - fp: 3.9655 - loss: 0.1025 - precision: 0.9716 - recall: 0.9545 - tn: 98.7931 - tp: 130.0345 - val_accuracy: 0.8468 - val_auc: 0.9263 - val_fn: 32.0000 - val_fp: 2.0000 - val_loss: 0.9750 - val_precision: 0.9800 - val_recall: 0.7538 - val_tn: 90.0000 - val_tp: 98.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9406 - auc: 0.9763 - fn: 8.0690 - fp: 6.5862 - loss: 0.2097 - precision: 0.9586 - recall: 0.9452 - tn: 89.1034 - tp: 135.6897 - val_accuracy: 0.8964 - val_auc: 0.9457 - val_fn: 13.0000 - val_fp: 10.0000 - val_loss: 0.5064 - val_precision: 0.9213 - val_recall: 0.9000 - val_tn: 82.0000 - val_tp: 117.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9593 - auc: 0.9948 - fn: 6.0000 - fp: 4.4483 - loss: 0.0998 - precision: 0.9664 - recall: 0.9590 - tn: 99.6207 - tp: 129.3793 - val_accuracy: 0.9054 - val_auc: 0.9515 - val_fn: 11.0000 - val_fp: 10.0000 - val_loss: 0.4288 - val_precision: 0.9225 - val_recall: 0.9154 - val_tn: 82.0000 - val_tp: 119.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9825 - auc: 0.9988 - fn: 2.6552 - fp: 2.1034 - loss: 0.0540 - precision: 0.9875 - recall: 0.9834 - tn: 94.0690 - tp: 140.6207 - val_accuracy: 0.9144 - val_auc: 0.9504 - val_fn: 13.0000 - val_fp: 6.0000 - val_loss: 0.4841 - val_precision: 0.9512 - val_recall: 0.9000 - val_tn: 86.0000 - val_tp: 117.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9925 - auc: 0.9998 - fn: 0.3793 - fp: 1.8966 - loss: 0.0338 - precision: 0.9889 - recall: 0.9984 - tn: 97.5172 - tp: 139.6552 - val_accuracy: 0.9144 - val_auc: 0.9590 - val_fn: 9.0000 - val_fp: 10.0000 - val_loss: 0.4128 - val_precision: 0.9237 - val_recall: 0.9308 - val_tn: 82.0000 - val_tp: 121.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9727 - auc: 0.9980 - fn: 3.4138 - fp: 3.9310 - loss: 0.0604 - precision: 0.9738 - recall: 0.9786 - tn: 97.5172 - tp: 134.5862 - val_accuracy: 0.8874 - val_auc: 0.9466 - val_fn: 23.0000 - val_fp: 2.0000 - val_loss: 0.6784 - val_precision: 0.9817 - val_recall: 0.8231 - val_tn: 90.0000 - val_tp: 107.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9888 - auc: 0.9995 - fn: 1.2069 - fp: 1.6552 - loss: 0.0381 - precision: 0.9896 - recall: 0.9917 - tn: 95.0000 - tp: 141.5862 - val_accuracy: 0.8874 - val_auc: 0.9518 - val_fn: 22.0000 - val_fp: 3.0000 - val_loss: 0.6177 - val_precision: 0.9730 - val_recall: 0.8308 - val_tn: 89.0000 - val_tp: 108.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9917 - auc: 0.9997 - fn: 0.9310 - fp: 1.7586 - loss: 0.0400 - precision: 0.9903 - recall: 0.9954 - tn: 98.6207 - tp: 138.1379 - val_accuracy: 0.8559 - val_auc: 0.9399 - val_fn: 30.0000 - val_fp: 2.0000 - val_loss: 0.8218 - val_precision: 0.9804 - val_recall: 0.7692 - val_tn: 90.0000 - val_tp: 100.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9176 - auc: 0.9770 - fn: 7.9655 - fp: 11.5172 - loss: 0.2088 - precision: 0.9181 - recall: 0.9414 - tn: 89.8621 - tp: 130.1035 - val_accuracy: 0.8964 - val_auc: 0.9471 - val_fn: 8.0000 - val_fp: 15.0000 - val_loss: 0.4951 - val_precision: 0.8905 - val_recall: 0.9385 - val_tn: 77.0000 - val_tp: 122.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9546 - auc: 0.9900 - fn: 4.5172 - fp: 6.5862 - loss: 0.1276 - precision: 0.9504 - recall: 0.9717 - tn: 94.2069 - tp: 134.1379 - val_accuracy: 0.7613 - val_auc: 0.9249 - val_fn: 52.0000 - val_fp: 1.0000 - val_loss: 1.1807 - val_precision: 0.9873 - val_recall: 0.6000 - val_tn: 91.0000 - val_tp: 78.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9218 - auc: 0.9832 - fn: 9.5517 - fp: 7.7586 - loss: 0.1682 - precision: 0.9486 - recall: 0.9198 - tn: 90.1724 - tp: 131.9655 - val_accuracy: 0.8378 - val_auc: 0.9394 - val_fn: 34.0000 - val_fp: 2.0000 - val_loss: 0.7660 - val_precision: 0.9796 - val_recall: 0.7385 - val_tn: 90.0000 - val_tp: 96.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9244 - auc: 0.9846 - fn: 7.9655 - fp: 10.4828 - loss: 0.1660 - precision: 0.9336 - recall: 0.9439 - tn: 87.2414 - tp: 133.7586 - val_accuracy: 0.8829 - val_auc: 0.9398 - val_fn: 7.0000 - val_fp: 19.0000 - val_loss: 0.5060 - val_precision: 0.8662 - val_recall: 0.9462 - val_tn: 73.0000 - val_tp: 123.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9534 - auc: 0.9945 - fn: 4.3448 - fp: 6.7586 - loss: 0.0930 - precision: 0.9528 - recall: 0.9734 - tn: 89.6207 - tp: 138.7241 - val_accuracy: 0.9099 - val_auc: 0.9544 - val_fn: 6.0000 - val_fp: 14.0000 - val_loss: 0.4312 - val_precision: 0.8986 - val_recall: 0.9538 - val_tn: 78.0000 - val_tp: 124.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - auc: 0.9992 - fn: 1.9655 - fp: 0.4828 - loss: 0.0520 - precision: 0.9978 - recall: 0.9886 - tn: 95.5517 - tp: 141.4483 - val_accuracy: 0.9009 - val_auc: 0.9464 - val_fn: 19.0000 - val_fp: 3.0000 - val_loss: 0.5768 - val_precision: 0.9737 - val_recall: 0.8538 - val_tn: 89.0000 - val_tp: 111.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9874 - auc: 0.9983 - fn: 2.0345 - fp: 1.3103 - loss: 0.0541 - precision: 0.9930 - recall: 0.9844 - tn: 102.3103 - tp: 133.7931 - val_accuracy: 0.9099 - val_auc: 0.9527 - val_fn: 16.0000 - val_fp: 4.0000 - val_loss: 0.5229 - val_precision: 0.9661 - val_recall: 0.8769 - val_tn: 88.0000 - val_tp: 114.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - auc: 0.9998 - fn: 0.9655 - fp: 0.9310 - loss: 0.0409 - precision: 0.9948 - recall: 0.9956 - tn: 100.9310 - tp: 136.6207 - val_accuracy: 0.9324 - val_auc: 0.9532 - val_fn: 9.0000 - val_fp: 6.0000 - val_loss: 0.4410 - val_precision: 0.9528 - val_recall: 0.9308 - val_tn: 86.0000 - val_tp: 121.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - auc: 0.9999 - fn: 0.4138 - fp: 1.0000 - loss: 0.0294 - precision: 0.9949 - recall: 0.9980 - tn: 101.2414 - tp: 136.7931 - val_accuracy: 0.9234 - val_auc: 0.9565 - val_fn: 9.0000 - val_fp: 8.0000 - val_loss: 0.4404 - val_precision: 0.9380 - val_recall: 0.9308 - val_tn: 84.0000 - val_tp: 121.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9848 - auc: 0.9995 - fn: 1.8966 - fp: 2.1379 - loss: 0.0402 - precision: 0.9850 - recall: 0.9896 - tn: 95.7931 - tp: 139.6207 - val_accuracy: 0.9054 - val_auc: 0.9513 - val_fn: 6.0000 - val_fp: 15.0000 - val_loss: 0.4541 - val_precision: 0.8921 - val_recall: 0.9538 - val_tn: 77.0000 - val_tp: 124.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9925 - auc: 0.9996 - fn: 1.5862 - fp: 0.9310 - loss: 0.0345 - precision: 0.9958 - recall: 0.9915 - tn: 97.2759 - tp: 139.6552 - val_accuracy: 0.9189 - val_auc: 0.9456 - val_fn: 12.0000 - val_fp: 6.0000 - val_loss: 0.5559 - val_precision: 0.9516 - val_recall: 0.9077 - val_tn: 86.0000 - val_tp: 118.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9860 - auc: 0.9995 - fn: 1.0690 - fp: 2.3448 - loss: 0.0376 - precision: 0.9831 - recall: 0.9932 - tn: 96.6897 - tp: 139.3448 - val_accuracy: 0.9099 - val_auc: 0.9483 - val_fn: 12.0000 - val_fp: 8.0000 - val_loss: 0.5204 - val_precision: 0.9365 - val_recall: 0.9077 - val_tn: 84.0000 - val_tp: 118.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9913 - auc: 0.9998 - fn: 1.8621 - fp: 0.5862 - loss: 0.0282 - precision: 0.9968 - recall: 0.9884 - tn: 96.8966 - tp: 140.1035 - val_accuracy: 0.9009 - val_auc: 0.9451 - val_fn: 18.0000 - val_fp: 4.0000 - val_loss: 0.6163 - val_precision: 0.9655 - val_recall: 0.8615 - val_tn: 88.0000 - val_tp: 112.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9915 - auc: 0.9998 - fn: 1.2414 - fp: 0.8276 - loss: 0.0286 - precision: 0.9958 - recall: 0.9890 - tn: 102.5862 - tp: 134.7931 - val_accuracy: 0.9189 - val_auc: 0.9476 - val_fn: 12.0000 - val_fp: 6.0000 - val_loss: 0.4955 - val_precision: 0.9516 - val_recall: 0.9077 - val_tn: 86.0000 - val_tp: 118.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - auc: 0.9997 - fn: 2.4828 - fp: 0.7931 - loss: 0.0309 - precision: 0.9962 - recall: 0.9830 - tn: 98.3448 - tp: 137.8276 - val_accuracy: 0.9189 - val_auc: 0.9505 - val_fn: 11.0000 - val_fp: 7.0000 - val_loss: 0.4759 - val_precision: 0.9444 - val_recall: 0.9154 - val_tn: 85.0000 - val_tp: 119.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9917 - auc: 0.9997 - fn: 1.3448 - fp: 0.6897 - loss: 0.0301 - precision: 0.9958 - recall: 0.9901 - tn: 97.9310 - tp: 139.4828 - val_accuracy: 0.9234 - val_auc: 0.9428 - val_fn: 11.0000 - val_fp: 6.0000 - val_loss: 0.5035 - val_precision: 0.9520 - val_recall: 0.9154 - val_tn: 86.0000 - val_tp: 119.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9939 - auc: 1.0000 - fn: 0.3103 - fp: 0.9310 - loss: 0.0219 - precision: 0.9913 - recall: 0.9987 - tn: 96.2414 - tp: 141.9655 - val_accuracy: 0.9279 - val_auc: 0.9448 - val_fn: 12.0000 - val_fp: 4.0000 - val_loss: 0.5454 - val_precision: 0.9672 - val_recall: 0.9077 - val_tn: 88.0000 - val_tp: 118.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9997 - auc: 1.0000 - fn: 0.1379 - fp: 0.0000e+00 - loss: 0.0162 - precision: 1.0000 - recall: 0.9995 - tn: 98.3793 - tp: 140.9310 - val_accuracy: 0.9054 - val_auc: 0.9415 - val_fn: 14.0000 - val_fp: 7.0000 - val_loss: 0.5182 - val_precision: 0.9431 - val_recall: 0.8923 - val_tn: 85.0000 - val_tp: 116.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.3448 - loss: 0.0193 - precision: 0.9985 - recall: 1.0000 - tn: 101.1724 - tp: 137.9310 - val_accuracy: 0.9144 - val_auc: 0.9395 - val_fn: 13.0000 - val_fp: 6.0000 - val_loss: 0.6276 - val_precision: 0.9512 - val_recall: 0.9000 - val_tn: 86.0000 - val_tp: 117.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9662 - auc: 0.9955 - fn: 5.3448 - fp: 4.8621 - loss: 0.0758 - precision: 0.9742 - recall: 0.9695 - tn: 91.1724 - tp: 138.0690 - val_accuracy: 0.8874 - val_auc: 0.9429 - val_fn: 9.0000 - val_fp: 16.0000 - val_loss: 0.5238 - val_precision: 0.8832 - val_recall: 0.9308 - val_tn: 76.0000 - val_tp: 121.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9775 - auc: 0.9972 - fn: 3.3448 - fp: 3.4138 - loss: 0.0610 - precision: 0.9811 - recall: 0.9800 - tn: 97.4483 - tp: 135.2414 - val_accuracy: 0.9099 - val_auc: 0.9530 - val_fn: 17.0000 - val_fp: 3.0000 - val_loss: 0.5525 - val_precision: 0.9741 - val_recall: 0.8692 - val_tn: 89.0000 - val_tp: 113.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9834 - auc: 0.9990 - fn: 2.9310 - fp: 2.2414 - loss: 0.0440 - precision: 0.9874 - recall: 0.9830 - tn: 103.0345 - tp: 131.2414 - val_accuracy: 0.8829 - val_auc: 0.9397 - val_fn: 24.0000 - val_fp: 2.0000 - val_loss: 0.9251 - val_precision: 0.9815 - val_recall: 0.8154 - val_tn: 90.0000 - val_tp: 106.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9431 - auc: 0.9902 - fn: 7.5517 - fp: 7.2759 - loss: 0.1400 - precision: 0.9557 - recall: 0.9478 - tn: 91.0000 - tp: 133.6207 - val_accuracy: 0.8559 - val_auc: 0.9322 - val_fn: 9.0000 - val_fp: 23.0000 - val_loss: 0.6461 - val_precision: 0.8403 - val_recall: 0.9308 - val_tn: 69.0000 - val_tp: 121.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8547 - auc: 0.9108 - fn: 18.3448 - fp: 18.4828 - loss: 0.7187 - precision: 0.8862 - recall: 0.8594 - tn: 82.7931 - tp: 119.8276 - val_accuracy: 0.8153 - val_auc: 0.9054 - val_fn: 24.0000 - val_fp: 17.0000 - val_loss: 0.9247 - val_precision: 0.8618 - val_recall: 0.8154 - val_tn: 75.0000 - val_tp: 106.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9476 - auc: 0.9878 - fn: 4.6897 - fp: 8.3448 - loss: 0.1457 - precision: 0.9423 - recall: 0.9712 - tn: 91.0345 - tp: 135.3793 - val_accuracy: 0.8243 - val_auc: 0.9120 - val_fn: 36.0000 - val_fp: 3.0000 - val_loss: 1.0218 - val_precision: 0.9691 - val_recall: 0.7231 - val_tn: 89.0000 - val_tp: 94.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9112 - auc: 0.9741 - fn: 10.1379 - fp: 13.2069 - loss: 0.2137 - precision: 0.9164 - recall: 0.9338 - tn: 87.0345 - tp: 129.0690 - val_accuracy: 0.7793 - val_auc: 0.8992 - val_fn: 47.0000 - val_fp: 2.0000 - val_loss: 1.4981 - val_precision: 0.9765 - val_recall: 0.6385 - val_tn: 90.0000 - val_tp: 83.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9386 - auc: 0.9888 - fn: 6.8276 - fp: 6.2759 - loss: 0.1492 - precision: 0.9557 - recall: 0.9409 - tn: 93.6897 - tp: 132.6552 - val_accuracy: 0.9189 - val_auc: 0.9520 - val_fn: 12.0000 - val_fp: 6.0000 - val_loss: 0.8040 - val_precision: 0.9516 - val_recall: 0.9077 - val_tn: 86.0000 - val_tp: 118.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9835 - auc: 0.9986 - fn: 3.5862 - fp: 1.2759 - loss: 0.0579 - precision: 0.9939 - recall: 0.9787 - tn: 94.4138 - tp: 140.1724 - val_accuracy: 0.8604 - val_auc: 0.9476 - val_fn: 27.0000 - val_fp: 4.0000 - val_loss: 0.9267 - val_precision: 0.9626 - val_recall: 0.7923 - val_tn: 88.0000 - val_tp: 103.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9688 - auc: 0.9970 - fn: 4.4828 - fp: 3.0690 - loss: 0.0784 - precision: 0.9826 - recall: 0.9680 - tn: 89.0000 - tp: 142.8965 - val_accuracy: 0.9054 - val_auc: 0.9535 - val_fn: 10.0000 - val_fp: 11.0000 - val_loss: 0.7154 - val_precision: 0.9160 - val_recall: 0.9231 - val_tn: 81.0000 - val_tp: 120.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9626 - auc: 0.9965 - fn: 4.8276 - fp: 2.6552 - loss: 0.0886 - precision: 0.9691 - recall: 0.9651 - tn: 99.1379 - tp: 132.8276 - val_accuracy: 0.9189 - val_auc: 0.9509 - val_fn: 9.0000 - val_fp: 9.0000 - val_loss: 0.7366 - val_precision: 0.9308 - val_recall: 0.9308 - val_tn: 83.0000 - val_tp: 121.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9904 - auc: 0.9998 - fn: 1.1379 - fp: 1.2759 - loss: 0.0332 - precision: 0.9915 - recall: 0.9917 - tn: 97.9310 - tp: 139.1035 - val_accuracy: 0.9144 - val_auc: 0.9533 - val_fn: 13.0000 - val_fp: 6.0000 - val_loss: 0.7902 - val_precision: 0.9512 - val_recall: 0.9000 - val_tn: 86.0000 - val_tp: 117.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9949 - auc: 0.9999 - fn: 0.7241 - fp: 0.8621 - loss: 0.0263 - precision: 0.9959 - recall: 0.9954 - tn: 98.1724 - tp: 139.6897 - val_accuracy: 0.9099 - val_auc: 0.9468 - val_fn: 17.0000 - val_fp: 3.0000 - val_loss: 0.8922 - val_precision: 0.9741 - val_recall: 0.8692 - val_tn: 89.0000 - val_tp: 113.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9970 - auc: 0.9999 - fn: 0.0690 - fp: 0.7931 - loss: 0.0225 - precision: 0.9954 - recall: 0.9997 - tn: 91.5172 - tp: 147.0690 - val_accuracy: 0.9054 - val_auc: 0.9483 - val_fn: 17.0000 - val_fp: 4.0000 - val_loss: 0.8551 - val_precision: 0.9658 - val_recall: 0.8692 - val_tn: 88.0000 - val_tp: 113.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9903 - auc: 1.0000 - fn: 0.1379 - fp: 1.7241 - loss: 0.0265 - precision: 0.9851 - recall: 0.9995 - tn: 93.8276 - tp: 143.7586 - val_accuracy: 0.9099 - val_auc: 0.9486 - val_fn: 15.0000 - val_fp: 5.0000 - val_loss: 0.8433 - val_precision: 0.9583 - val_recall: 0.8846 - val_tn: 87.0000 - val_tp: 115.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - auc: 1.0000 - fn: 0.6207 - fp: 0.3448 - loss: 0.0202 - precision: 0.9986 - recall: 0.9966 - tn: 96.6552 - tp: 141.8276 - val_accuracy: 0.9009 - val_auc: 0.9447 - val_fn: 20.0000 - val_fp: 2.0000 - val_loss: 0.9553 - val_precision: 0.9821 - val_recall: 0.8462 - val_tn: 90.0000 - val_tp: 110.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9918 - auc: 1.0000 - fn: 0.9655 - fp: 0.6897 - loss: 0.0277 - precision: 0.9970 - recall: 0.9884 - tn: 101.2759 - tp: 136.5172 - val_accuracy: 0.8964 - val_auc: 0.9427 - val_fn: 20.0000 - val_fp: 3.0000 - val_loss: 1.0192 - val_precision: 0.9735 - val_recall: 0.8462 - val_tn: 89.0000 - val_tp: 110.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9981 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.5862 - loss: 0.0218 - precision: 0.9969 - recall: 1.0000 - tn: 98.5862 - tp: 140.2759 - val_accuracy: 0.9099 - val_auc: 0.9457 - val_fn: 15.0000 - val_fp: 5.0000 - val_loss: 0.8894 - val_precision: 0.9583 - val_recall: 0.8846 - val_tn: 87.0000 - val_tp: 115.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - auc: 1.0000 - fn: 0.7241 - fp: 0.3793 - loss: 0.0176 - precision: 0.9983 - recall: 0.9955 - tn: 97.7241 - tp: 140.6207 - val_accuracy: 0.9099 - val_auc: 0.9450 - val_fn: 17.0000 - val_fp: 3.0000 - val_loss: 0.9445 - val_precision: 0.9741 - val_recall: 0.8692 - val_tn: 89.0000 - val_tp: 113.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 0.0140 - precision: 1.0000 - recall: 1.0000 - tn: 100.8621 - tp: 138.5862 - val_accuracy: 0.9009 - val_auc: 0.9463 - val_fn: 16.0000 - val_fp: 6.0000 - val_loss: 0.8863 - val_precision: 0.9500 - val_recall: 0.8769 - val_tn: 86.0000 - val_tp: 114.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 0.0184 - precision: 1.0000 - recall: 1.0000 - tn: 93.6207 - tp: 145.8276 - val_accuracy: 0.9099 - val_auc: 0.9433 - val_fn: 17.0000 - val_fp: 3.0000 - val_loss: 0.9662 - val_precision: 0.9741 - val_recall: 0.8692 - val_tn: 89.0000 - val_tp: 113.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 0.0160 - precision: 1.0000 - recall: 1.0000 - tn: 100.3103 - tp: 139.1379 - val_accuracy: 0.9144 - val_auc: 0.9440 - val_fn: 13.0000 - val_fp: 6.0000 - val_loss: 0.9287 - val_precision: 0.9512 - val_recall: 0.9000 - val_tn: 86.0000 - val_tp: 117.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.2759 - loss: 0.0113 - precision: 0.9989 - recall: 1.0000 - tn: 94.4138 - tp: 144.7586 - val_accuracy: 0.9009 - val_auc: 0.9464 - val_fn: 20.0000 - val_fp: 2.0000 - val_loss: 1.0777 - val_precision: 0.9821 - val_recall: 0.8462 - val_tn: 90.0000 - val_tp: 110.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 0.0142 - precision: 1.0000 - recall: 1.0000 - tn: 97.5172 - tp: 141.9310 - val_accuracy: 0.9009 - val_auc: 0.9424 - val_fn: 16.0000 - val_fp: 6.0000 - val_loss: 0.9677 - val_precision: 0.9500 - val_recall: 0.8769 - val_tn: 86.0000 - val_tp: 114.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.3103 - loss: 0.0124 - precision: 0.9987 - recall: 1.0000 - tn: 96.2759 - tp: 142.8621 - val_accuracy: 0.8829 - val_auc: 0.9352 - val_fn: 24.0000 - val_fp: 2.0000 - val_loss: 1.2503 - val_precision: 0.9815 - val_recall: 0.8154 - val_tn: 90.0000 - val_tp: 106.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9970 - auc: 0.9998 - fn: 0.0000e+00 - fp: 0.7586 - loss: 0.0261 - precision: 0.9950 - recall: 1.0000 - tn: 97.9655 - tp: 140.7241 - val_accuracy: 0.9009 - val_auc: 0.9433 - val_fn: 18.0000 - val_fp: 4.0000 - val_loss: 1.0351 - val_precision: 0.9655 - val_recall: 0.8615 - val_tn: 88.0000 - val_tp: 112.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.6207 - loss: 0.0141 - precision: 0.9966 - recall: 1.0000 - tn: 98.1724 - tp: 140.6552 - val_accuracy: 0.9234 - val_auc: 0.9439 - val_fn: 13.0000 - val_fp: 4.0000 - val_loss: 0.9798 - val_precision: 0.9669 - val_recall: 0.9000 - val_tn: 88.0000 - val_tp: 117.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.1379 - loss: 0.0095 - precision: 0.9995 - recall: 1.0000 - tn: 100.5517 - tp: 138.7586 - val_accuracy: 0.9144 - val_auc: 0.9456 - val_fn: 13.0000 - val_fp: 6.0000 - val_loss: 0.9439 - val_precision: 0.9512 - val_recall: 0.9000 - val_tn: 86.0000 - val_tp: 117.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 0.0101 - precision: 1.0000 - recall: 1.0000 - tn: 100.1034 - tp: 139.3448 - val_accuracy: 0.9054 - val_auc: 0.9394 - val_fn: 18.0000 - val_fp: 3.0000 - val_loss: 1.1403 - val_precision: 0.9739 - val_recall: 0.8615 - val_tn: 89.0000 - val_tp: 112.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 0.0109 - precision: 1.0000 - recall: 1.0000 - tn: 95.9310 - tp: 143.5172 - val_accuracy: 0.9099 - val_auc: 0.9421 - val_fn: 17.0000 - val_fp: 3.0000 - val_loss: 1.0981 - val_precision: 0.9741 - val_recall: 0.8692 - val_tn: 89.0000 - val_tp: 113.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - auc: 1.0000 - fn: 0.0000e+00 - fp: 0.0000e+00 - loss: 0.0107 - precision: 1.0000 - recall: 1.0000 - tn: 92.5172 - tp: 146.9310 - val_accuracy: 0.9234 - val_auc: 0.9435 - val_fn: 14.0000 - val_fp: 3.0000 - val_loss: 1.0721 - val_precision: 0.9748 - val_recall: 0.8923 - val_tn: 89.0000 - val_tp: 116.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - auc: 1.0000 - fn: 0.6207 - fp: 0.0000e+00 - loss: 0.0130 - precision: 1.0000 - recall: 0.9965 - tn: 98.9310 - tp: 139.8965 - val_accuracy: 0.8874 - val_auc: 0.9378 - val_fn: 22.0000 - val_fp: 3.0000 - val_loss: 1.2012 - val_precision: 0.9730 - val_recall: 0.8308 - val_tn: 89.0000 - val_tp: 108.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - auc: 1.0000 - fn: 0.8966 - fp: 0.0000e+00 - loss: 0.0168 - precision: 1.0000 - recall: 0.9956 - tn: 100.4828 - tp: 138.0690 - val_accuracy: 0.9234 - val_auc: 0.9464 - val_fn: 11.0000 - val_fp: 6.0000 - val_loss: 1.0227 - val_precision: 0.9520 - val_recall: 0.9154 - val_tn: 86.0000 - val_tp: 119.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9881 - auc: 0.9998 - fn: 0.5862 - fp: 1.7241 - loss: 0.0245 - precision: 0.9822 - recall: 0.9975 - tn: 95.4828 - tp: 141.6552 - val_accuracy: 0.8829 - val_auc: 0.9154 - val_fn: 24.0000 - val_fp: 2.0000 - val_loss: 1.5269 - val_precision: 0.9815 - val_recall: 0.8154 - val_tn: 90.0000 - val_tp: 106.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9736 - auc: 0.9985 - fn: 4.0345 - fp: 2.6207 - loss: 0.0565 - precision: 0.9870 - recall: 0.9674 - tn: 98.3793 - tp: 134.4138 - val_accuracy: 0.8649 - val_auc: 0.9344 - val_fn: 28.0000 - val_fp: 2.0000 - val_loss: 1.4911 - val_precision: 0.9808 - val_recall: 0.7846 - val_tn: 90.0000 - val_tp: 102.0000\n"
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, matthews_corrcoef, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - accuracy: 0.8866 - auc: 0.9302 - fn: 15.7500 - fp: 1.0000 - loss: 1.0736 - precision: 0.9893 - recall: 0.8017 - tn: 58.7500 - tp: 64.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4911452531814575,\n",
       " 102.0,\n",
       " 2.0,\n",
       " 90.0,\n",
       " 28.0,\n",
       " 0.8648648858070374,\n",
       " 0.9807692170143127,\n",
       " 0.7846153974533081,\n",
       " 0.9344481825828552]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "MCC: 0.7531\n",
      "Accuracy: 0.8649\n",
      "Precision: 0.9808\n",
      "Recall: 0.7846\n",
      "F1: 0.8718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86        92\n",
      "           1       0.98      0.78      0.87       130\n",
      "\n",
      "    accuracy                           0.86       222\n",
      "   macro avg       0.87      0.88      0.86       222\n",
      "weighted avg       0.89      0.86      0.87       222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "print(\"MCC:\", np.round(matthews_corrcoef(y_test, y_pred), 4))\n",
    "print(\"Accuracy:\", np.round(accuracy_score(y_test, y_pred), 4))\n",
    "print(\"Precision:\", np.round(precision_score(y_test, y_pred), 4))\n",
    "print(\"Recall:\", np.round(recall_score(y_test, y_pred), 4))\n",
    "print(\"F1:\", np.round(f1_score(y_test, y_pred), 4))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f03b6930350>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
